{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec34964-e53f-49d1-bd2e-3c84257f7ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install bs4 sentence-transformers tqdm langchain_community tiktoken langchain-openai langchainhub chromadb langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94658a9f-9156-4432-bbf7-5547e9a1c654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import requests\n",
    "import bs4\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from langchain.llms.base import LLM\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import PyPDFLoader, WebBaseLoader, GoogleDriveLoader, UnstructuredWordDocumentLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI  # Uses OpenAI-compatible API\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb40f71-d897-4055-a8eb-d3e23824dbfc",
   "metadata": {},
   "source": [
    "**Helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceb38446-6146-41f6-84d4-7798de8345d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading pdf contents\n",
    "def load_pdf(path: str):\n",
    "    loader = PyPDFLoader(path)\n",
    "    return loader.load()\n",
    "\n",
    "def load_word(path: str):\n",
    "    return UnstructuredWordDocumentLoader(path).load()\n",
    "    \n",
    "# loading website contents\n",
    "def load_web(path: str):\n",
    "    loader = WebBaseLoader(\n",
    "        web_path = (path,),\n",
    "        bs_kwargs = dict(\n",
    "          parse_only = bs4.SoupStrainer(\n",
    "              class_ = (\"post-content\", \"post-title\", \"post-header\") # depending on CSS class\n",
    "          )  \n",
    "        ),\n",
    "    )\n",
    "    return loader\n",
    "\n",
    "# loading google doc contents (see below)\n",
    "\n",
    "def normalize(text):\n",
    "    return re.sub(r'[^a-z]', '', str(text).lower())\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "def extract_json_from_llm_output(output: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts and parses a JSON object from LLM output that may include Markdown formatting.\n",
    "    Handles triple backticks, optional language labels, and excessive whitespace.\n",
    "    \"\"\"\n",
    "    output = output.strip()\n",
    "\n",
    "    # Match content between ```json ... ``` or just ``` ... ```\n",
    "    match = re.search(r\"```(?:json)?\\s*(\\{.*?\\})\\s*```\", output, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        json_str = match.group(1)\n",
    "    else:\n",
    "        json_str = output\n",
    "\n",
    "    return json.loads(json_str)\n",
    "\n",
    "def get_doc_id(url):\n",
    "    return url.split(\"/\")[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ecbdfe-e90d-4107-b067-5d0b1c906c38",
   "metadata": {},
   "source": [
    "OpenAI embeddings don't work in HK (even with VPN). Hence, HuggingFace embedding model was used. Also feel free to test out API calls from DeepSeep or replace it with your choice of LLM for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9351f27e-9f8a-4ee3-ba55-f1689883be5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10312\\3436719414.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embd = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "C:\\Users\\User\\rag-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embd = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Using DeepSeek as LLM\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_base=\"https://api.deepseek.com/v1\",\n",
    "    openai_api_key=\"\", # your API key\n",
    "    model=\"deepseek-chat\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13af1e95-3503-4f6b-980e-7d3dda4510a6",
   "metadata": {},
   "source": [
    "For lower latency, switch to AWS Bedrock models. In here, Llama 70B Instruct was used. You may need to prepare your own credentials in a \".env\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "fdcb8938-fa73-4b0d-81f6-405334f2e1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from langchain_aws.llms.bedrock import BedrockLLM\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration change to bedrock llmAWS_REGION = os.getenv(\"AWS_REGION\", \"ap-south-1\")\n",
    "MODEL_ID = \"meta.llama3-70b-instruct-v1:0\"\n",
    "MODEL_PARAMS = {\n",
    "    \"temperature\": 0.2,\n",
    "    \"top_p\": 0.9\n",
    "}\n",
    "\n",
    "def setup_llm():\n",
    "    \"\"\"Set up and return the AWS Bedrock LLM.\"\"\"\n",
    "    # Set up AWS Bedrock client\n",
    "    bedrock_runtime = boto3.client(\n",
    "        service_name=\"bedrock-runtime\",\n",
    "        region_name=AWS_REGION\n",
    "    )\n",
    "\n",
    "    # Initialize Llama-3-70B-instruct model\n",
    "    llm = BedrockLLM(\n",
    "        client=bedrock_runtime,\n",
    "        model_id=MODEL_ID,\n",
    "        model_kwargs=MODEL_PARAMS\n",
    "    )\n",
    "    \n",
    "    return llm\n",
    "\n",
    "llm = setup_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "dee50444-8d61-458e-bc20-5bc1a007ef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# load spacy models\n",
    "nlp_textcat = spacy.load(\"spaCy/textcat_model\")\n",
    "nlp_ner = spacy.load(\"spaCy/ner_model\")\n",
    "nlp_ner_food = spacy.load(\"spaCy/ner_food_model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b52757-b688-41af-ae35-fbfa1f376195",
   "metadata": {},
   "source": [
    "**Intermediate Step: Preparing Google Cloud API**\n",
    "- for loading contents of Google Docs\n",
    "- you can also try loading content using **load_pdf()** and **load_web**\n",
    "- the code below uses my Google Cloud credentials included in this folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b249a1e4-5085-430d-97bd-b00cd1fc87b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade google-auth google-auth-oauthlib google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04c57334-5b2e-4a03-8472-1f15330825b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=808603111555-e7db6vhbucu4hj1ovgmd01ikvsnqn8ul.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A52225%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.readonly&state=urGcMPuC2LXklegz4rE1qcXPpuFTuJ&access_type=offline\n",
      "✅ token.json generated successfully.\n"
     ]
    }
   ],
   "source": [
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "\n",
    "# Correct scope\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive.readonly']\n",
    "\n",
    "def generate_token():\n",
    "    flow = InstalledAppFlow.from_client_secrets_file('credentials_google.json', SCOPES)\n",
    "    creds = flow.run_local_server(port=0)\n",
    "\n",
    "    with open('token.json', 'w') as token:\n",
    "        token.write(creds.to_json())\n",
    "\n",
    "    print(\"✅ token.json generated successfully.\")\n",
    "\n",
    "generate_token()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2009ded1-d845-4a7c-b0b1-d0e360bc2ddd",
   "metadata": {},
   "source": [
    "doc_links contains the Google Docs from the Sommelier Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93df9f04-79ca-459b-b80d-e9a5e11f2944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10312\\1336585303.py:18: LangChainDeprecationWarning: The class `GoogleDriveLoader` was deprecated in LangChain 0.0.32 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-google-community package and should be used instead. To use it run `pip install -U :class:`~langchain-google-community` and import as `from :class:`~langchain_google_community import GoogleDriveLoader``.\n",
      "  g_docs = GoogleDriveLoader(\n"
     ]
    }
   ],
   "source": [
    "docs_links = [\n",
    "    \"https://docs.google.com/document/d/1MvX9CTrVcoWg7WLAscq2MmnhTIrR0hZIGkpJMqhgflo/edit?tab=t.0\",\n",
    "    \"https://docs.google.com/document/d/1NcV9_JGjMfA4WlihW3vNTduy24NBWdy1RWXrA2W0BIk/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/193rx2Rh6u-Ud40k-rgnqSQs-94SvHdeXPrPxOWK59X0/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1vRDsn5o5mdymOEJ_O0tS4wcOjsAjt_2mLZqFfvgDUOs/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1JceLBII727AZzSrDFfdGthJ1G4PhCDsA8sEm_dQMVr0/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1yonU4qcysNkgd0BvbFmeIW9NF2ARErRJVW8QZynJyvM/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1bq2AE1Jy6cQFt1xgjqtkof12Lw6F6fujqTlN1nZnh0A/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1i-OcQeo7XOG83gS2ay2u0SLMWs4f8FG0JE_7l87qJkw/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1PyZE8v3S3aUY66lFn97q0vaXDHc60lyso2oUFP0htjY/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1Dudd7-6yl_UQrxfGa3MJZlKOfzHQdqWg0fb8Z9RzBec/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1cjhrhCccuwiIh0ujj8QeamJ2JHhI6CjPmO84t1DSRZ0/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1ESlfU6v8jseFlllZb3eaUeCJt69EIMsZiyMrDac-wX8/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1xQhAkC3oP2cb262EjaHCV6CxEgeEGUsKrC8pH2p6RiY/edit?usp=sharing\"\n",
    "    \n",
    "]\n",
    "\n",
    "g_docs = GoogleDriveLoader(\n",
    "    document_ids = [get_doc_id(i) for i in docs_links],\n",
    "    credentials_path = \"credentials_google.json\",\n",
    "    token_path = \"token.json\"\n",
    ").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f9dba0-a5b4-44db-8266-0f3e324d0674",
   "metadata": {},
   "source": [
    "Chroma seems to be a convenient alternative, as a chroma vectorstore can be converted directly into a retriever that returns k relevant documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8c95311-858e-4c5d-b856-b7b9ff4ba5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading sample pdf document\n",
    "path = \"wine_food_pairing_knowledge.pdf\"\n",
    "word = load_pdf(path)\n",
    "g_docs = g_docs + word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b795521-0dc5-49c4-bc4e-c527627787e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size = 300, \n",
    "    chunk_overlap = 50\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(g_docs)\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents = splits,\n",
    "    embedding = embd\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d77ae9-9457-4958-8bfd-25f627b52ac5",
   "metadata": {},
   "source": [
    "**Preparing Pydantic Schemas and LLM Modelfiles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "06316cfb-4c7d-4c0a-983e-c503104dd92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# define simple schema as template, map doc.ent if present else None\n",
    "class WineMetadata(BaseModel):\n",
    "    \"\"\"Schema for metadata filters\"\"\"\n",
    "    wine_name: Optional[str] = Field(default = None, description = \"Specific wine name mentioned in query\")\n",
    "    max_price: Optional[float] = Field(default = None, description = \"Specific max price mentioned in the query\")\n",
    "    min_price: Optional[float] = Field(default = None, description = \"Specific min price mentioned in the query\")\n",
    "    wine_type: Optional[str] = Field(default = None, description = \"Specific wine type (e.g., white, red, sparkling, etc.)\")\n",
    "\n",
    "\n",
    "# Base Models for Reverse Pairings\n",
    "class FoodMetadata(BaseModel):\n",
    "    \"\"\"Structured metadata filters for querying a food product database.\"\"\"\n",
    "    \n",
    "    dish_name: Optional[str] = Field(\n",
    "        default=None, description=\"Name of the dish (e.g., 'roast duck', 'brie cheese').\"\n",
    "    )\n",
    "    min_price: Optional[float] = Field(\n",
    "        default=None, description=\"Minimum price filter (inclusive).\"\n",
    "    )\n",
    "    max_price: Optional[float] = Field(\n",
    "        default=None, description=\"Maximum price filter (inclusive).\"\n",
    "    )\n",
    "    food_type: Optional[str] = Field(\n",
    "        default=None, description=\"Food type (e.g., 'fruit', 'pastry', 'vegetarian').\"\n",
    "    )\n",
    "    course: Optional[str] = Field(\n",
    "        default=None, description=\"Course (e.g., 'starter', 'main', 'dessert').\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5b3951ec-46df-4018-8cc7-1be920c9ecec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for generating taste profiles\n",
    "\n",
    "wine_system = \"\"\"You are a master-level sommelier and wine data expert.\n",
    "Your task is to create a hypothetical, ideal wine profile in the form of structured metadata based on a user's preference, question, or context.\n",
    "\n",
    "This wine does not have to exist — it should represent the best possible match for what the user is looking for.\n",
    "\n",
    "You must output a plausible, detailed JSON object that aligns with the schema below.\n",
    "\n",
    "ONLY return the JSON. Do not explain, comment, or refer to the query.\n",
    "\n",
    "JSON Format:\n",
    "\n",
    "{\n",
    "  \"wine_name\": \"str\",              // Specific wine name mentioned\n",
    "  \"winemaker\": \"str\",              // Name of the winemaker or producer\n",
    "  \"vintage\": \"int\",                // Vintage year (e.g. 2015)\n",
    "  \"country\": \"str\",                // Country of origin\n",
    "  \"region\": \"str\",                 // Region or appellation\n",
    "  \"wine_type\": \"str\",              // Type of wine (e.g. red, white, rosé, sparkling)\n",
    "  \"wine_grapes\": \"str\",            // Grape variety or blend (e.g. Merlot, Syrah)\n",
    "  \"occasion\": \"str\",               // Occasion suitability (e.g. \"wedding\", \"gift\", \"everyday\")\n",
    "  \"body\": \"str\",                   // Body type (e.g. \"light\", \"full-bodied\")\n",
    "  \"acidity\": \"str\",                // Acidity level (e.g. \"crisp\", \"low\")\n",
    "  \"alcohol\": \"float\",              // Alcohol content (as percentage, e.g. 13.5)\n",
    "  \"fruitiness\": \"str\",             // Level of fruitiness (e.g. \"dry\", \"juicy\")\n",
    "  \"minerality\": \"str\",             // Presence of mineral notes (e.g. \"chalky\", \"flinty\")\n",
    "  \"sweetness\": \"str\",              // Sweetness level (e.g. \"dry\", \"semi-sweet\", \"sweet\")\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "food_system = \"\"\"You are a master-level chef and food data expert.\n",
    "Your task is to create a hypothetical, ideal food profile in the form of structured metadata based on a user's preference, question, or context.\n",
    "\n",
    "This food does not have to exist — it should represent the best possible match for what the user is looking for.\n",
    "\n",
    "You must output a plausible, detailed JSON object that aligns with the schema below.\n",
    "\n",
    "ONLY return the JSON. Do not explain, comment, or refer to the query.\n",
    "\n",
    "JSON Format:\n",
    "{\n",
    "    \"dish_name\": \"str\",\n",
    "    \"food_type\": \"str\",                  // e.g. 'meat', 'vegetarian', 'pastry'\n",
    "    \"course\": \"str\",                // e.g. 'starter', 'main', 'dessert'\n",
    "    \"regional_pairing\": \"str\",     // e.g. 'Provence', 'Piedmont'\n",
    "    \"sweetness\": \"str\",            // 1–10\n",
    "    \"salitiness\": \"str\",           // 1–10\n",
    "    \"acidity\": \"str\",              // 1–10\n",
    "    \"sourness\": \"str\",             // 1–10\n",
    "    \"umami\": \"str\"                 // 1–10\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "50d4b3ff-daa1-44dd-b7d1-1f08f38275f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINE_FIELD_MAP = {\n",
    "    \"wine_name\": \"Product Name\",\n",
    "    \"min_price\": \"WS Retail Price\",\n",
    "    \"max_price\": \"WS Retail Price\",\n",
    "    \"wine_type\": \"Wine Type\",\n",
    "}\n",
    "\n",
    "FOOD_FIELD_MAP = {\n",
    "    \"dish_name\": \"Product Name\",\n",
    "    \"min_price\": \"Price\",\n",
    "    \"max_price\": \"Price\",\n",
    "    \"food_type\": \"Food Type\",\n",
    "    \"course\": \"Course\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb01f672-e880-49cd-986f-60930b18919d",
   "metadata": {},
   "source": [
    "**More helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "27dcfc86-f16d-4a6f-8a4a-ef84714bdc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwatch\n",
    "import time\n",
    "import random\n",
    "from statistics import quantiles\n",
    "from functools import wraps\n",
    "\n",
    "def timed(log_times):\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            start = time.time()\n",
    "            result = func(*args, **kwargs)\n",
    "            end = time.time()\n",
    "            log_times[func.__name__] = round(end - start, 4)\n",
    "            return result\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "wine_log_times = {}\n",
    "food_log_times = {}\n",
    "\n",
    "\n",
    "# identify if the intent is to recommend food or wine\n",
    "def recommend_wine(query:str):\n",
    "    category = nlp_textcat(query)\n",
    "    recommend_wine = category.cats[\"recommend_wine\"]\n",
    "    recommend_food = category.cats[\"recommend_food\"]\n",
    "    if recommend_wine > recommend_food:\n",
    "        return True\n",
    "    else:\n",
    "        # print(\"recommend food\")\n",
    "        return False\n",
    "\n",
    "def get_price(wine, price_field=\"price\"):\n",
    "    price_str = wine.get(price_field, \"0\")\n",
    "    if not isinstance(price_str, str):\n",
    "        price_str = str(price_str)\n",
    "    # Remove commas, spaces, and common currency symbols\n",
    "    cleaned = price_str.replace(\",\", \"\").replace(\" \", \"\").replace(\"$\", \"\").replace(\"HKD\", \"\")\n",
    "    try:\n",
    "        return float(cleaned)\n",
    "    except (ValueError, TypeError):\n",
    "        return 0.0\n",
    "\n",
    "# for listed prices such as 150 - 200\n",
    "def parse_average_price(value):\n",
    "    if isinstance(value, str):\n",
    "        value = value.strip()\n",
    "        # Match range: \"150-200\", \"150 - 200\"\n",
    "        range_match = re.match(r\"^(\\d+)\\s*-\\s*(\\d+)$\", value)\n",
    "        if range_match:\n",
    "            low, high = map(float, range_match.groups())\n",
    "            return (low + high) / 2\n",
    "        # Match single number: \"150\"\n",
    "        elif re.match(r\"^\\d+(\\.\\d+)?$\", value):\n",
    "            return float(value)\n",
    "    return None\n",
    "\n",
    "def sample_quartiles(wines, price_field=\"price\", k_per_quartile=10):\n",
    "    prices = [get_price(w, price_field) for w in wines]\n",
    "    if not prices:\n",
    "        return []\n",
    "\n",
    "    q1, q2, q3 = quantiles(prices, n=4)\n",
    "\n",
    "    buckets = {\n",
    "        \"Q1\": [w for w in wines if get_price(w, price_field) <= q1],\n",
    "        \"Q2\": [w for w in wines if q1 < get_price(w, price_field) <= q2],\n",
    "        \"Q3\": [w for w in wines if q2 < get_price(w, price_field) <= q3],\n",
    "        \"Q4\": [w for w in wines if q3 < get_price(w, price_field)]\n",
    "    }\n",
    "\n",
    "    sampled = []\n",
    "    for group in buckets.values():\n",
    "        if group:\n",
    "            sampled.extend(random.sample(group, min(k_per_quartile, len(group))))\n",
    "    return sampled                         \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5214a3de-43aa-4182-b156-3342d7eac221",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Main functions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d81edb5f-e1f8-4d22-8eec-f4d64cd53514",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timed(wine_log_times)\n",
    "def wine_query_analyzer(query: str):\n",
    "    \"\"\" Extracts structured wine metadata from a natural language query\n",
    "    using a spaCy NER model and returns it as a WineMetadata object.\"\"\"\n",
    "    \n",
    "    doc = nlp_ner(query)\n",
    "    all_labels = nlp_ner.get_pipe(\"ner\").labels\n",
    "    result = {label: None for label in all_labels}\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if (ent.label_ == \"min_price\") or (ent.label_ == \"max_price\"):\n",
    "            result[ent.label_] = float(ent.text)\n",
    "        elif (ent.label_ == \"wine_type\"):\n",
    "            if ent.text in [\"red\", \"white\", \"sparkling\"]:\n",
    "                result[ent.label_] = ent.text\n",
    "            else:\n",
    "                result[ent.label_] = None \n",
    "        else:\n",
    "            result[ent.label_] = ent.text\n",
    "        \n",
    "    print(result)\n",
    "    return WineMetadata(**result)\n",
    "\n",
    "@timed(food_log_times)\n",
    "def food_query_analyzer(query: str):\n",
    "    \"\"\" Extracts structured food metadata from a natural language query\n",
    "    using a spaCy NER model and returns it as a FoodMetadata object.\"\"\"\n",
    "    \n",
    "    doc = nlp_ner_food(query)\n",
    "    all_labels = nlp_ner_food.get_pipe(\"ner\").labels\n",
    "    result = {label: None for label in all_labels}\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if (ent.label_ == \"min_price\") or (ent.label_ == \"max_price\"):\n",
    "            result[ent.label_] = float(ent.text)\n",
    "        # below codes are for labels with discrete values (e.g., type = {starter, main, dessert, etc.} \n",
    "        # to prevent unwanted values\n",
    "        \n",
    "        # elif (ent.label_ == \"\"):\n",
    "        #     if ent.text in [\"\", \"\", \"\"]:\n",
    "        #         result[ent.label_] = ent.text\n",
    "        #     else:\n",
    "        #         result[ent.label_] = None \n",
    "        \n",
    "        else:\n",
    "            result[ent.label_] = ent.text\n",
    "        \n",
    "    print(result)\n",
    "    return FoodMetadata(**result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1ae98a79-0efc-47bd-a4fb-bf6d776dcfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timed(wine_log_times)\n",
    "def filter_wines(data, model_instance, field_map, max_results=20):\n",
    "    \"\"\"\n",
    "    Given metadata filters constructed from user query using LLM,\n",
    "    returns first n wine profiles that match. Also includes fallback logic\n",
    "    \"\"\"\n",
    "    filters = model_instance.model_dump(exclude_none=True)\n",
    "    results = []\n",
    "    price_field = \"WS Retail Price\"\n",
    "\n",
    "    # identify filter state\n",
    "    has_filters = bool(filters)\n",
    "    has_price = \"min_price\" in filters or \"max_price\" in filters\n",
    "    has_type = \"wine_type\" in filters\n",
    "    \n",
    "    # case 1: have both filters\n",
    "    if has_filters and ( has_price ):\n",
    "        for wine in data:\n",
    "            match = True\n",
    "            for key, value in filters.items():\n",
    "    \n",
    "                if key not in field_map:\n",
    "                    # print(f\"{key} not in field map\")\n",
    "                    continue\n",
    "                    \n",
    "                if key in (\"min_price\", \"max_price\"):\n",
    "                    wine_price = get_price(wine, price_field)\n",
    "                    # print(f\"wine: {wine['Product Name']}. wine price: {wine_price}\")\n",
    "                    if key == \"min_price\" and wine_price < value:\n",
    "                        # print(f\"wine: {wine['Product Name']}. less than min -> wine price: {wine_price}\")\n",
    "                        match = False\n",
    "                        break\n",
    "                    if key == \"max_price\" and wine_price > value:\n",
    "                        # print(f\"wine: {wine['Product Name']}. above max -> wine price: {wine_price}\")\n",
    "                        match = False\n",
    "                        break\n",
    "    \n",
    "                else:\n",
    "                    field = field_map.get(key)\n",
    "                    if field not in wine:\n",
    "                        # print(f\"wine: {wine['Product Name']}. {field} not in wine\")\n",
    "                        match = False\n",
    "                        break\n",
    "                    wine_val = normalize(wine[field])\n",
    "                    query_val = normalize(value)\n",
    "                    if query_val not in wine_val:\n",
    "                        # print(f\"wine: {wine['Product Name']}. {query_val} not in {wine_val}\")\n",
    "                        match = False\n",
    "                        break\n",
    "    \n",
    "            if match:\n",
    "                results.append(wine)\n",
    "                if len(results)== max_results:\n",
    "                    break\n",
    "        # print(f\"Case 1:\", results)\n",
    "        return results\n",
    "\n",
    "    # case 2: filter only has wine_type (no price)\n",
    "    elif has_type and not has_price:\n",
    "        wine_type = normalize(filters[\"wine_type\"])\n",
    "        type_filtered = [w for w in data if normalize(w.get(field_map[\"wine_type\"], \"\")) == wine_type]\n",
    "        # print(f\"Case 2:\", sample_quartiles(type_filtered, price_field=price_field, k_per_quartile=4))\n",
    "        return sample_quartiles(type_filtered, price_field=price_field, k_per_quartile=4)\n",
    "\n",
    "    else:\n",
    "        type_buckets = {\n",
    "            \"red\": [],\n",
    "            \"white\": [],\n",
    "            \"sparkling\": []\n",
    "        }\n",
    "        for w in data:\n",
    "            wt = normalize(w.get(field_map.get(\"wine_type\", \"wine_type\"), \"\"))\n",
    "            if wt in type_buckets:\n",
    "                type_buckets[wt].append(w)\n",
    "\n",
    "        sampled = []\n",
    "        sampled += sample_quartiles(type_buckets[\"red\"], price_field, k_per_quartile=10)\n",
    "        sampled += sample_quartiles(type_buckets[\"white\"], price_field, k_per_quartile=10)\n",
    "        sampled += sample_quartiles(type_buckets[\"sparkling\"], price_field, k_per_quartile=10)\n",
    "        # print(f\"Case 3:\", sampled[:max_results])\n",
    "        return sampled[:max_results]\n",
    "\n",
    "\n",
    "# Uncomment below if using DeepSeek API call (i.e., SystemMessage, HumanMessage)\n",
    "\n",
    "# @timed(wine_log_times)\n",
    "# def create_wine_taste_profile(query: str):\n",
    "#     \"\"\"\n",
    "#     Generates a hypothetical document embedding (HyDE) of \n",
    "#     the ideal taste profile based on user query.\n",
    "#     \"\"\"\n",
    "#     messages = [\n",
    "#         SystemMessage(content=system),\n",
    "#         HumanMessage(content=query)\n",
    "#     ]\n",
    "#     response = llm.invoke(messages)\n",
    "#     print(response.content + \"\\n\")\n",
    "    \n",
    "#     return response.content   \n",
    "\n",
    "\n",
    "@timed(wine_log_times)\n",
    "def create_wine_taste_profile(query: str):\n",
    "    \"\"\"\n",
    "    Generates a hypothetical document embedding (HyDE) of \n",
    "    the ideal taste profile based on user query.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"{food_system}\n",
    "User Query: {query.strip()}\n",
    "\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)  \n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "    \n",
    "@timed(wine_log_times)\n",
    "def generate_wine_recommendations(filtered, profile, top_k=5):\n",
    "    \"\"\"\n",
    "    Performs similarity search between embeddings of (a) each of the filtered wines\n",
    "    and (b) enriched taste profile from query, if present otherwise randomly \n",
    "    sample 3 wines (cheapest -> middle -> most expensive)\n",
    "    \"\"\"\n",
    "    if len(filtered) == 0:\n",
    "        return None\n",
    "        \n",
    "    if len(filtered) < top_k:\n",
    "        return filtered\n",
    "        \n",
    "    if profile:\n",
    "        # print(\"PROFILE:\", profile)\n",
    "        embedded_wines = []\n",
    "        for wine in filtered:\n",
    "            content = \"\\n\".join(f\"{key}: {value}\" for key, value in wine.items() if value)\n",
    "            wine_embed = embd.embed_query(content)\n",
    "            embedded_wines.append((wine, wine_embed))\n",
    "\n",
    "        profile_embed = embd.embed_query(profile)\n",
    "        scored_embed = [(wine, cosine_similarity(profile_embed, wine_embed)) for wine, wine_embed in embedded_wines]\n",
    "        top_wines = sorted(scored_embed, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "        return [wine for wine, _ in top_wines]\n",
    "\n",
    "    else:\n",
    "        # print(\"Empty Profile\")\n",
    "        sorted_wines = sorted(filtered, key=lambda x: float(x.WS_Retail_Price))\n",
    "        n = len(sorted_wines)\n",
    "        if n == 0:\n",
    "            return []\n",
    "        step = max(1, n // top_k)\n",
    "        sampled = [random.choice(sorted_wines[i:i+step]) for i in range(0, n, step)][:top_k]\n",
    "\n",
    "        return sampled \n",
    "\n",
    "def ask_wine_ai(question, data, field_map):\n",
    "    start_main = time.time()\n",
    "    parsed_query = wine_query_analyzer(question)\n",
    "    filtered = filter_wines(data=data, model_instance=parsed_query, field_map=field_map)\n",
    "    profile = create_wine_taste_profile(question)\n",
    "    recommendations = generate_wine_recommendations(filtered, profile)\n",
    "\n",
    "    # Print timing summary\n",
    "    total_time = round(time.time() - start_main, 4)\n",
    "    print(\"Timing summary:\")\n",
    "\n",
    "    for name, duration in wine_log_times.items():\n",
    "        print(f\"  {name}: {duration} seconds\")\n",
    "        \n",
    "    print(f\"  Total time: {total_time} seconds\")\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "935edbcb-db8a-402a-a9c7-9a9d97919698",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timed(food_log_times)\n",
    "def filter_food(data, model_instance, field_map, max_results=20):\n",
    "    \"\"\"\n",
    "    Given metadata filters constructed from user query using LLM,\n",
    "    returns first n food taste profiles that match. Also includes fallback logic\n",
    "    \"\"\"\n",
    "    filters = model_instance.model_dump(exclude_none=True)\n",
    "    results = []\n",
    "    price_field = \"Price\"\n",
    "\n",
    "    # identify filter state\n",
    "    has_filters = bool(filters)\n",
    "    has_price = \"min_price\" in filters or \"max_price\" in filters\n",
    "    has_type = \"food_type\" in filters\n",
    "    has_course = \"course\" in filters  # implement course logic\n",
    "    \n",
    "    # case 1: have both price and type filters\n",
    "    if has_filters and ( len(filters) > 1 or has_price ):\n",
    "        for food in data:\n",
    "            match = True\n",
    "            for key, value in filters.items():\n",
    "    \n",
    "                if key not in field_map:\n",
    "                    # print(f\"{key} not in field map\")\n",
    "                    continue\n",
    "                    \n",
    "                if key in (\"min_price\", \"max_price\"):\n",
    "                    food_price = get_price(food, price_field)\n",
    "                    # print(f\"food: {food['Product Name']}. food price: {food_price}\")\n",
    "                    if key == \"min_price\" and food_price < value:\n",
    "                        match = False\n",
    "                        # print(f\"food: {food['Product Name']}. less than min -> food price: {food_price}\")\n",
    "                        break\n",
    "                    if key == \"max_price\" and food_price > value:\n",
    "                        match = False\n",
    "                        # print(f\"food: {food['Product Name']}. greater than max -> food price: {food_price}\")\n",
    "                        break\n",
    "    \n",
    "                else:\n",
    "                    field = field_map.get(key)\n",
    "                    if field not in food:\n",
    "                        # print(f\"{field} not in food\")\n",
    "                        match = False\n",
    "                        break\n",
    "                    food_val = normalize(food[field])\n",
    "                    query_val = normalize(value)\n",
    "                    if query_val not in food_val:\n",
    "                        # print(f\"{query_val} not in {food_val}\")\n",
    "                        match = False\n",
    "                        break\n",
    "    \n",
    "            if match:\n",
    "                results.append(food)\n",
    "                if len(results)== max_results:\n",
    "                    break\n",
    "        # print(\"Case 1:\", results)\n",
    "        return results\n",
    "\n",
    "    # case 2: filter only has food_type (no price)\n",
    "    elif has_type and not has_price:\n",
    "        food_type = normalize(filters[\"food_type\"])\n",
    "        type_filtered = [w for w in data if normalize(w.get(field_map[\"food_type\"], \"\")) == food_type]\n",
    "        # print(\"Case 2:\", sample_quartiles(type_filtered, price_field=price_field, k_per_quartile=4))\n",
    "        return sample_quartiles(type_filtered, price_field=price_field, k_per_quartile=4)\n",
    "\n",
    "    # temp fallback: choose randomly from beef, chicken, and pork dishes\n",
    "    else:\n",
    "        type_buckets = {\n",
    "            \"beef\": [],\n",
    "            \"chicken\": [],\n",
    "            \"pork\": []\n",
    "        }\n",
    "        for w in data:\n",
    "            wt = normalize(w.get(field_map.get(\"food_type\", \"food_type\"), \"\"))\n",
    "            if wt in type_buckets:\n",
    "                type_buckets[wt].append(w)\n",
    "\n",
    "        sampled = []\n",
    "        sampled += sample_quartiles(type_buckets[\"beef\"], price_field, k_per_quartile=10)\n",
    "        sampled += sample_quartiles(type_buckets[\"chicken\"], price_field, k_per_quartile=10)\n",
    "        sampled += sample_quartiles(type_buckets[\"pork\"], price_field, k_per_quartile=10)\n",
    "        # print(\"Case 3:\", sampled[:max_results])\n",
    "        return sampled[:max_results]\n",
    "\n",
    "\n",
    "@timed(food_log_times)\n",
    "def create_food_taste_profile(query: str):\n",
    "    \"\"\"\n",
    "    Generates a hypothetical document embedding (HyDE) of \n",
    "    the ideal taste profile based on user query.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"{food_system}\n",
    "User Query: {query.strip()}\n",
    "\"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return response\n",
    "    \n",
    "@timed(food_log_times)\n",
    "def generate_food_recommendations(filtered, profile, top_k=5):\n",
    "    \"\"\"\n",
    "    Performs similarity search between embeddings of (a) each of the filtered dishes\n",
    "    and (b) enriched taste profile from query, if present otherwise randomly \n",
    "    sample 3 dishes (cheapest -> middle -> most expensive)\n",
    "    \"\"\"\n",
    "    if len(filtered) == 0:\n",
    "        return None\n",
    "        \n",
    "    if len(filtered) < top_k:\n",
    "        return filtered\n",
    "        \n",
    "    if profile:\n",
    "        embedded_food = []\n",
    "        for food in filtered:\n",
    "            content = \"\\n\".join(f\"{key}: {value}\" for key, value in food.items() if value)\n",
    "            food_embed = embd.embed_query(content)\n",
    "            embedded_food.append((food, food_embed))\n",
    "\n",
    "        profile_embed = embd.embed_query(profile)\n",
    "        scored_embed = [(food, cosine_similarity(profile_embed, food_embed)) for food, food_embed in embedded_food]\n",
    "        top_dishes = sorted(scored_embed, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "        return [dish for dish, _ in top_dishes]\n",
    "\n",
    "    else:\n",
    "        # Clean and sort\n",
    "        filtered_clean = [\n",
    "            item for item in filtered\n",
    "            if parse_average_price(item[\"Price\"]) is not None\n",
    "        ]\n",
    "        \n",
    "        sorted_food = sorted(\n",
    "            filtered_clean,\n",
    "            key=lambda x: parse_average_price(x[\"Price\"])\n",
    "        )\n",
    "\n",
    "        n = len(sorted_food)\n",
    "        if n == 0:\n",
    "            return []\n",
    "        step = max(1, n // top_k)\n",
    "        sampled = [random.choice(sorted_food[i:i+step]) for i in range(0, n, step)][:top_k]\n",
    "\n",
    "        return sampled \n",
    "\n",
    "def ask_food_ai(question, data, field_map):\n",
    "    start_main = time.time()\n",
    "    parsed_query = food_query_analyzer(question)\n",
    "    filtered = filter_food(data=data, model_instance=parsed_query, field_map=field_map)\n",
    "    profile = create_food_taste_profile(question)\n",
    "    recommendations = generate_food_recommendations(filtered, profile)\n",
    "\n",
    "    # Print timing summary\n",
    "    total_time = round(time.time() - start_main, 4)\n",
    "    print(\"Timing summary:\")\n",
    "\n",
    "    for name, duration in food_log_times.items():\n",
    "        print(f\"  {name}: {duration} seconds\")\n",
    "        \n",
    "    print(f\"  Total time: {total_time} seconds\")\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "bb9f1484-bf16-484b-977f-35fc18b7f06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations(query: str):\n",
    "    # Case 1: user looking for wine recommendations\n",
    "    if recommend_wine(query):\n",
    "        print(query) \n",
    "        recommendations = ask_wine_ai(question=query, data=wine_json, field_map=WINE_FIELD_MAP)\n",
    "        if recommendations == None:\n",
    "            print(\"No recommendations found\")\n",
    "            return \n",
    "    \n",
    "        for j in range(5):\n",
    "            try:\n",
    "                print(f\"Wine {j+1}:\", recommendations[j]['Product Name'])\n",
    "            except:\n",
    "                print(\"No more suggested wines\")\n",
    "                break\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    \n",
    "    # Case 2: user looking for food recommendations\n",
    "    else:\n",
    "        print(query)  \n",
    "        recommendations = ask_food_ai(question=query, data = food_json, field_map = FOOD_FIELD_MAP)\n",
    "        if recommendations == None:\n",
    "            print(\"No recommendation found\")\n",
    "            return\n",
    "        \n",
    "        for j in range(5):\n",
    "            try:\n",
    "                print(f\"Food {j+1}:\", recommendations[j]['Product Name'])\n",
    "            except:\n",
    "                print(\"No more suggested food\")\n",
    "                break\n",
    "        print(\"\\n\")\n",
    "\n",
    "    return recommendations\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de58ecd0-4781-41ec-878b-e9cdeb57af9e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Load the wine and food databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf8b1294-abe1-41b0-be5a-34fd8cd70ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data = \"wine_data.csv\"\n",
    "food_data = \"food_data.csv\"\n",
    "\n",
    "wine_df = pd.read_csv(wine_data)\n",
    "food_df = pd.read_csv(food_data)\n",
    "\n",
    "wine_json = wine_df.to_dict(orient=\"records\")\n",
    "food_json = food_df.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2400d945-5488-49db-b195-b514f979d3ec",
   "metadata": {},
   "source": [
    "### Wine-Food Pairing Tests\n",
    "\n",
    "Questions:\n",
    "1. What wine goes well with spicy Thai green curry with coconut milk?\n",
    "2. Recommend a red wine under 300 HKD that pairs well with grilled lamb and comes from Spain\n",
    "3. Suggest a celebratory wine that works with oysters and has high acidity.\n",
    "4. I'm cooking mushroom risotto and want something medium-bodied and earthy to go with it.\n",
    "5. Pair a bold Napa Cabernet Sauvignon with sushi.\n",
    "\n",
    "### Food-Wine Pairing Tests\n",
    "\n",
    "Questions\n",
    "1. What are the best dishes to serve with a 2020 Puligny-Montrachet Chardonnay?\n",
    "2. I have a bottle of Amarone della Valpolicella — what foods would pair well with it?\n",
    "3. What should I cook for dinner to go with a chilled bottle of Sancerre?\n",
    "4. Can you suggest a full-course meal to go with a vintage Champagne?\n",
    "5. What kind of food works well with a sweet Riesling from Mosel?\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "03a70aca-c588-47ec-99d9-81c4facf3423",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_question = \"Recommend a red wine under 300 HKD that pairs well with grilled lamb and is from Spain\"\n",
    "food_question = \"What are the main course dishes under 200 HKD to serve with a 2020 Puligny-Montrachet Chardonnay?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "d4366b51-a0a7-4a59-9fc2-4c219f751d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommend a red wine under 300 HKD that pairs well with grilled lamb and is from Spain\n",
      "{'max_price': 300.0, 'min_price': None, 'wine_name': None, 'wine_type': 'red'}\n",
      "Timing summary:\n",
      "  filter_wines: 0.0 seconds\n",
      "  create_wine_taste_profile: 1.7029 seconds\n",
      "  generate_wine_recommendations: 2.0107 seconds\n",
      "  Total time: 3.7165 seconds\n",
      "Wine 1: Luis Felipe Edwards LFE 900 Colchagua Valley 2018\n",
      "Wine 2: La Rioja Alta, Vina Alberdi Reserva 2019\n",
      "Wine 3: Te Mata Awatea Cabernet Merlot, Hawkes Bay 2019\n",
      "Wine 4: Domaine des Jeunes Pousses Beaujolais dEmeringes Replat de Vavre 2021\n",
      "Wine 5: Te Mata Estate Cabernet Merlot 2020\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wine_recommendations = generate_recommendations(wine_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "db3f17f9-efb5-493e-b695-48db57eff2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the main course dishes under 200 HKD to serve with a 2020 Puligny-Montrachet Chardonnay?\n",
      "{'course': 'main course', 'dish_name': None, 'food_type': '2020', 'max_price': 200.0, 'min_price': None}\n",
      "Timing summary:\n",
      "  filter_food: 0.0019 seconds\n",
      "  create_food_taste_profile: 1.6623 seconds\n",
      "  generate_food_recommendations: 1.9563 seconds\n",
      "  Total time: 3.6275 seconds\n",
      "Food 1: Chicken Parmesan with Spaghetti and Marinara Sauce\n",
      "Food 2: Bobotie\n",
      "Food 3: Chilean-Style Empanadas with Chorizo and Manchego Cheese\n",
      "Food 4: Caramelized Onion and Garlic Quiche with Fresh Thyme\n",
      "Food 5: Chilean-Style Churrasco with Chimichurri Sauce\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "food_recommendations = generate_recommendations(food_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e9c065-a266-4292-95a0-ab95dc0509ca",
   "metadata": {},
   "source": [
    "### RAG-based Reasoning\n",
    "Now we develop the RAG feature, in which relevant documents from the knowledge database will be retrieved. \n",
    "\n",
    "**Steps**\n",
    "1. Create an instruction prompt for the DeepSeek-based LLM\n",
    "2. Embed user query\n",
    "3. Use Chroma-based retrieval of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b2dcba34-6791-41a8-bf9c-9dc06f913416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(query: str, retriever, k=5):\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    context = \"\\n\".join([doc.page_content for doc in docs])\n",
    "    return context\n",
    "\n",
    "\n",
    "def generate_reasoning(query, item_list, context, llm):\n",
    "    start_time = time.time()\n",
    "    results = []\n",
    "\n",
    "    for item in item_list:\n",
    "        prompt = f\"\"\"{reasoning_system}\n",
    "\n",
    "User Query: {query}\n",
    "Item: {item}\n",
    "Context: {context}\n",
    "\n",
    "Explain the pairing or recommendation:\"\"\"\n",
    "        \n",
    "        response = llm.invoke(prompt)\n",
    "        results.append({\"item\": item, \"explanation\": response.strip()})\n",
    "\n",
    "    print(f\"Time taken: {time.time() - start_time:.2f} seconds \\n\\n\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "294143e2-3018-481d-a511-f201a6a2309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_system = \"\"\"\n",
    "You are a world-class sommelier and culinary expert in wine and food pairings.\n",
    "Given a user query and a list of dishes or wines, explain why each item pairs well.\n",
    "Focus only on positive pairing notes. Keep each explanation to two sentences or less.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "e5d395e3-ea06-48fa-a84c-47d7a99fa4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_wine_secret(query, retriever=retriever, llm=llm, k=5):\n",
    "    # optional: can add functionality to access all database info about each recommended product\n",
    "    recommendations_list = [product[\"Product Name\"] for product in generate_recommendations(query)]\n",
    "    context = retrieve_context(query, retriever)\n",
    "    results = generate_reasoning(query=query, item_list=recommendations_list, context=context, llm=llm)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "0d19a89f-5185-424c-9f5e-529d906f1f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_question = \"Recommend a red wine under 300 HKD that pairs well with grilled lamb and is from Spain\"\n",
    "food_question = \"What are the main course dishes under 200 HKD to serve with a 2020 Puligny-Montrachet Chardonnay?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "0d70ec78-7beb-4527-ae8b-1ea4779a71ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wine Query\n",
      "Recommend a red wine under 300 HKD that pairs well with grilled lamb and is from Spain\n",
      "{'max_price': 300.0, 'min_price': None, 'wine_name': None, 'wine_type': 'red'}\n",
      "Timing summary:\n",
      "  filter_wines: 0.0 seconds\n",
      "  create_wine_taste_profile: 1.6752 seconds\n",
      "  generate_wine_recommendations: 1.9821 seconds\n",
      "  Total time: 3.6603 seconds\n",
      "Wine 1: Te Mata Awatea Cabernet Merlot, Hawkes Bay 2019\n",
      "Wine 2: Luis Felipe Edwards LFE 900 Colchagua Valley 2018\n",
      "Wine 3: La Rioja Alta, Vina Alberdi Reserva 2019\n",
      "Wine 4: Domaine des Jeunes Pousses Beaujolais dEmeringes Replat de Vavre 2021\n",
      "Wine 5: Te Mata Estate Cabernet Merlot 2020\n",
      "\n",
      "\n",
      "Time taken: 8.42 seconds \n",
      "\n",
      "\n",
      "Te Mata Awatea Cabernet Merlot, Hawkes Bay 2019: This wine does not meet the user's query as it is not from Spain and not under 300 HKD.\n",
      "\n",
      "Luis Felipe Edwards LFE 900 Colchagua Valley 2018: This Spanish red wine, Luis Felipe Edwards LFE 900 Colchagua Valley 2018, pairs well with grilled lamb due to its bold and full-bodied character. The wine's dark fruit flavors and robust tannins will complement the lamb's rich and savory flavors, creating a harmonious balance of intensity.\n",
      "\n",
      "La Rioja Alta, Vina Alberdi Reserva 2019: This Spanish red wine, La Rioja Alta, Vina Alberdi Reserva 2019, is an excellent pairing for grilled lamb due to its rich, full-bodied flavor profile and moderate tannins. The wine's dark fruit flavors and subtle spices will complement the lamb's smoky, savory flavors, while its acidity will help cut through the richness of the dish.\n",
      "\n",
      "Domaine des Jeunes Pousses Beaujolais dEmeringes Replat de Vavre 2021: The recommended wine is not from Spain, but I can suggest an alternative. For a red wine under 300 HKD that pairs well with grilled lamb and is from Spain, I recommend a Tempranillo from the Ribera del Duero region. This wine's bold, dark fruit flavors and moderate tannins will complement the rich, savory flavors of the grilled lamb. The wine's acidity will cut through the fattiness of the lamb, creating a well-balanced pairing.\n",
      "\n",
      "Te Mata Estate Cabernet Merlot 2020: This Spanish red wine, Te Mata Estate Cabernet Merlot 2020, is an excellent pairing for grilled lamb due to its bold, full-bodied structure and dark fruit flavors. The wine's tannin profile will complement the lamb's richness, while its fruit concentration will enhance the savory, umami flavors of the dish.\n",
      "--------------------\n",
      "Food Query\n",
      "What are the main course dishes under 200 HKD to serve with a 2020 Puligny-Montrachet Chardonnay?\n",
      "{'course': 'main course', 'dish_name': None, 'food_type': '2020', 'max_price': 200.0, 'min_price': None}\n",
      "Timing summary:\n",
      "  filter_food: 0.001 seconds\n",
      "  create_food_taste_profile: 1.6589 seconds\n",
      "  generate_food_recommendations: 1.9146 seconds\n",
      "  Total time: 3.5765 seconds\n",
      "Food 1: Bobotie\n",
      "Food 2: Chicken Parmesan with Spaghetti and Marinara Sauce\n",
      "Food 3: Chilean-Style Empanadas with Chorizo and Manchego Cheese\n",
      "Food 4: Chilean-Style Churrasco with Chimichurri Sauce\n",
      "Food 5: Caramelized Onion and Garlic Quiche with Fresh Thyme\n",
      "\n",
      "\n",
      "Time taken: 7.85 seconds \n",
      "\n",
      "\n",
      "Bobotie: Bobotie is a South African dish that combines sweet and savory flavors, which makes it an excellent match for the 2020 Puligny-Montrachet Chardonnay. The wine's citrus and stone fruit notes will complement the sweetness of the bobotie, while its crisp acidity will cut through the richness of the dish.\n",
      "\n",
      "Chicken Parmesan with Spaghetti and Marinara Sauce: The 2020 Puligny-Montrachet Chardonnay pairs well with the Chicken Parmesan with Spaghetti and Marinara Sauce because the wine's crisp acidity cuts through the richness of the dish, while its flavors of green apple and citrus complement the bright, herbal notes in the marinara sauce.\n",
      "\n",
      "Chilean-Style Empanadas with Chorizo and Manchego Cheese: This Chilean-Style Empanadas with Chorizo and Manchego Cheese pairs well with the 2020 Puligny-Montrachet Chardonnay because the wine's crisp acidity cuts through the richness of the chorizo and cheese, while its subtle oak notes complement the savory flavors of the empanada. The wine's citrus and green apple flavors also enhance the freshness and vibrancy of the dish.\n",
      "\n",
      "Chilean-Style Churrasco with Chimichurri Sauce: The 2020 Puligny-Montrachet Chardonnay pairs well with the Chilean-Style Churrasco with Chimichurri Sauce because the wine's bright acidity and subtle oak notes complement the dish's bold, smoky flavors and herbal notes from the chimichurri sauce. The wine's citrus and green apple flavors also enhance the grilled meat's richness and juiciness.\n",
      "\n",
      "Caramelized Onion and Garlic Quiche with Fresh Thyme: This Caramelized Onion and Garlic Quiche with Fresh Thyme pairs beautifully with the 2020 Puligny-Montrachet Chardonnay. The rich, buttery flavors of the quiche complement the wine's creamy texture and subtle oak notes, while the caramelized onions and fresh thyme add a sweet and herbaceous depth that enhances the wine's citrus and stone fruit flavors.\n"
     ]
    }
   ],
   "source": [
    "print(\"Wine Query\")\n",
    "wine_results = ask_wine_secret(wine_question)\n",
    "# print(\"\\n\\n\".join([f\"{product['item']}: {product['explanation']}\" for product in wine_results])) \n",
    "# print(\"-\" * 20)\n",
    "\n",
    "print(\"Food Query\")\n",
    "food_results = ask_wine_secret(food_question)\n",
    "# print(\"\\n\\n\".join([f\"{product['item']}: {product['explanation']}\" for product in food_results])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "833a87dd-5221-45f7-8fed-0893a6e57423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luis Felipe Edwards LFE 900 Colchagua Valley 2018: This Spanish red wine, Luis Felipe Edwards LFE 900 Colchagua Valley 2018, is an excellent pairing for grilled lamb due to its bold, full-bodied character and dark fruit flavors. The wine's robust tannins will complement the lamb's richness, while its fruit concentration will enhance the savory, umami flavors of the dish.\n",
      "\n",
      "La Rioja Alta, Vina Alberdi Reserva 2019: La Rioja Alta, Vina Alberdi Reserva 2019 is a Spanish red wine that pairs well with grilled lamb due to its rich, full-bodied flavor profile and moderate tannins. The wine's dark fruit flavors and subtle spices will complement the lamb's bold, savory flavors, while its acidity will help cut through the richness of the dish.\n",
      "\n",
      "Te Mata Awatea Cabernet Merlot, Hawkes Bay 2019: This wine does not meet the user's query as it is not from Spain and not under 300 HKD.\n",
      "\n",
      "Domaine des Jeunes Pousses Beaujolais dEmeringes Replat de Vavre 2021: This wine does not meet the user's query as it is not from Spain and not a red wine.\n",
      "\n",
      "Te Mata Estate Cabernet Merlot 2020: This Spanish red wine, Te Mata Estate Cabernet Merlot 2020, pairs well with grilled lamb due to its powerful structure and black fruit characteristics, which can match the intensity of the lamb. The wine's tannin structure benefits from protein interaction, while its fruit concentration complements the savory, umami-rich flavors of the lamb.\n"
     ]
    }
   ],
   "source": [
    "# print(wine_results)\n",
    "result = \"\\n\\n\".join([f\"{product['item']}: {product['explanation']}\" for product in wine_results])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec4bb2d-dd18-4910-83a8-2550fc047e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-env",
   "language": "python",
   "name": "rag-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
