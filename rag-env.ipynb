{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "058c0fc4-01ea-41de-9dc3-2fc9d755e75c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (0.1.7)\n",
      "Requirement already satisfied: langchainhub in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (0.1.21)\n",
      "Requirement already satisfied: chromadb in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (1.0.13)\n",
      "Requirement already satisfied: langchain in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (0.2.17)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from sentence-transformers) (4.52.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from sentence-transformers) (0.33.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.15.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from langchain_community) (2.0.38)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from langchain_community) (3.11.18)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from langchain_community) (0.2.43)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from langchain_community) (0.1.147)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from langchain) (0.2.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from langchain) (1.10.22)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.0->langchain_community) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (4.6.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.0.6)\n",
      "Requirement already satisfied: idna in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.24.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from langchain-openai) (1.88.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from langchainhub) (2.32.4.20250611)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from chromadb) (1.2.1)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from chromadb) (1.4.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from chromadb) (5.3.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from chromadb) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from chromadb) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from chromadb) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from chromadb) (1.34.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from chromadb) (1.73.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from chromadb) (0.15.2)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from chromadb) (33.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from chromadb) (4.23.0)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.20.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.40.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (24.12.23)\n",
      "Requirement already satisfied: protobuf in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.19.2)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.34.1 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.34.1 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.55b1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from beautifulsoup4->bs4) (2.6)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install bs4 sentence-transformers tqdm langchain_community tiktoken langchain-openai langchainhub chromadb langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94658a9f-9156-4432-bbf7-5547e9a1c654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import requests\n",
    "import bs4\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "import faiss\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from typing import Optional, List\n",
    "from langchain.llms.base import LLM\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import PyPDFLoader, WebBaseLoader, GoogleDriveLoader, UnstructuredWordDocumentLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI  # Uses OpenAI-compatible API\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb40f71-d897-4055-a8eb-d3e23824dbfc",
   "metadata": {},
   "source": [
    "**Helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceb38446-6146-41f6-84d4-7798de8345d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading pdf contents\n",
    "def load_pdf(path: str):\n",
    "    loader = PyPDFLoader(path)\n",
    "    return loader.load()\n",
    "\n",
    "def load_word(path: str):\n",
    "    return UnstructuredWordDocumentLoader(path).load()\n",
    "    \n",
    "# loading website contents\n",
    "def load_web(path: str):\n",
    "    loader = WebBaseLoader(\n",
    "        web_path = (path,),\n",
    "        bs_kwargs = dict(\n",
    "          parse_only = bs4.SoupStrainer(\n",
    "              class_ = (\"post-content\", \"post-title\", \"post-header\") # depending on CSS class\n",
    "          )  \n",
    "        ),\n",
    "    )\n",
    "    return loader\n",
    "\n",
    "# loading google doc contents (see below)\n",
    "\n",
    "def normalize(text):\n",
    "    return re.sub(r'[^a-z]', '', str(text).lower())\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "def extract_json_from_llm_output(output: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts and parses a JSON object from LLM output that may include Markdown formatting.\n",
    "    Handles triple backticks, optional language labels, and excessive whitespace.\n",
    "    \"\"\"\n",
    "    output = output.strip()\n",
    "\n",
    "    # Match content between ```json ... ``` or just ``` ... ```\n",
    "    match = re.search(r\"```(?:json)?\\s*(\\{.*?\\})\\s*```\", output, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        json_str = match.group(1)\n",
    "    else:\n",
    "        json_str = output\n",
    "\n",
    "    return json.loads(json_str)\n",
    "\n",
    "def get_doc_id(url):\n",
    "    return url.split(\"/\")[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ecbdfe-e90d-4107-b067-5d0b1c906c38",
   "metadata": {},
   "source": [
    "OpenAI embeddings don't work in HK (even with VPN). Hence, HuggingFace embedding model was used. Also feel free to test out API calls from DeepSeep or replace it with your choice of LLM for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9351f27e-9f8a-4ee3-ba55-f1689883be5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embd = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# change to bedrock llm\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_base=\"https://api.deepseek.com/v1\",\n",
    "    openai_api_key=\"sk-ea1868b36aa34a36be9a223e75c1c63c\", \n",
    "    model=\"deepseek-chat\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dee50444-8d61-458e-bc20-5bc1a007ef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# load spacy models\n",
    "nlp_textcat = spacy.load(\"spaCy/textcat_model\")\n",
    "nlp_ner = spacy.load(\"spaCy/ner_model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54a224b-d8f5-47b8-a339-77e587ad31bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9b52757-b688-41af-ae35-fbfa1f376195",
   "metadata": {},
   "source": [
    "**Intermediate Step: Preparing Google Cloud API**\n",
    "- for loading contents of Google Docs\n",
    "- you can also try loading content using **load_pdf()** and **load_web**\n",
    "- the code below uses my Google Cloud credentials included in this folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b249a1e4-5085-430d-97bd-b00cd1fc87b4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-auth in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (2.40.3)\n",
      "Collecting google-auth-oauthlib\n",
      "  Using cached google_auth_oauthlib-1.2.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-api-python-client\n",
      "  Downloading google_api_python_client-2.174.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from google-auth) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from google-auth) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from google-auth) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth) (0.6.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from google-auth-oauthlib) (2.0.0)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client)\n",
      "  Using cached httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client)\n",
      "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 (from google-api-python-client)\n",
      "  Using cached google_api_core-2.25.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client)\n",
      "  Using cached uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.70.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (5.29.5)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client)\n",
      "  Using cached proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2025.4.26)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.3.1)\n",
      "Using cached google_auth_oauthlib-1.2.2-py3-none-any.whl (19 kB)\n",
      "Downloading google_api_python_client-2.174.0-py3-none-any.whl (13.7 MB)\n",
      "   ---------------------------------------- 0.0/13.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.3/13.7 MB 6.1 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.9/13.7 MB 7.3 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.5/13.7 MB 8.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.9/13.7 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.6/13.7 MB 12.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.7/13.7 MB 11.9 MB/s eta 0:00:00\n",
      "Using cached google_api_core-2.25.1-py3-none-any.whl (160 kB)\n",
      "Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Using cached proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: uritemplate, proto-plus, httplib2, google-auth-oauthlib, google-auth-httplib2, google-api-core, google-api-python-client\n",
      "\n",
      "   ----- ---------------------------------- 1/7 [proto-plus]\n",
      "   ----- ---------------------------------- 1/7 [proto-plus]\n",
      "   ----- ---------------------------------- 1/7 [proto-plus]\n",
      "   ----- ---------------------------------- 1/7 [proto-plus]\n",
      "   ----------- ---------------------------- 2/7 [httplib2]\n",
      "   ----------- ---------------------------- 2/7 [httplib2]\n",
      "   ----------------- ---------------------- 3/7 [google-auth-oauthlib]\n",
      "   ----------------- ---------------------- 3/7 [google-auth-oauthlib]\n",
      "   ---------------------------- ----------- 5/7 [google-api-core]\n",
      "   ---------------------------- ----------- 5/7 [google-api-core]\n",
      "   ---------------------------- ----------- 5/7 [google-api-core]\n",
      "   ---------------------------- ----------- 5/7 [google-api-core]\n",
      "   ---------------------------- ----------- 5/7 [google-api-core]\n",
      "   ---------------------------- ----------- 5/7 [google-api-core]\n",
      "   ---------------------------- ----------- 5/7 [google-api-core]\n",
      "   ---------------------------- ----------- 5/7 [google-api-core]\n",
      "   ---------------------------- ----------- 5/7 [google-api-core]\n",
      "   ---------------------------- ----------- 5/7 [google-api-core]\n",
      "   ---------------------------------- ----- 6/7 [google-api-python-client]\n",
      "   ---------------------------------- ----- 6/7 [google-api-python-client]\n",
      "   ---------------------------------- ----- 6/7 [google-api-python-client]\n",
      "   ---------------------------------- ----- 6/7 [google-api-python-client]\n",
      "   ---------------------------------- ----- 6/7 [google-api-python-client]\n",
      "   ---------------------------------- ----- 6/7 [google-api-python-client]\n",
      "   ---------------------------------- ----- 6/7 [google-api-python-client]\n",
      "   ---------------------------------- ----- 6/7 [google-api-python-client]\n",
      "   ---------------------------------- ----- 6/7 [google-api-python-client]\n",
      "   ---------------------------------- ----- 6/7 [google-api-python-client]\n",
      "   ---------------------------------- ----- 6/7 [google-api-python-client]\n",
      "   ---------------------------------- ----- 6/7 [google-api-python-client]\n",
      "   ---------------------------------------- 7/7 [google-api-python-client]\n",
      "\n",
      "Successfully installed google-api-core-2.25.1 google-api-python-client-2.174.0 google-auth-httplib2-0.2.0 google-auth-oauthlib-1.2.2 httplib2-0.22.0 proto-plus-1.26.1 uritemplate-4.2.0\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade google-auth google-auth-oauthlib google-api-python-client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2009ded1-d845-4a7c-b0b1-d0e360bc2ddd",
   "metadata": {},
   "source": [
    "doc_links contains the Google Docs from the Sommelier Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93df9f04-79ca-459b-b80d-e9a5e11f2944",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_12072\\1336585303.py:18: LangChainDeprecationWarning: The class `GoogleDriveLoader` was deprecated in LangChain 0.0.32 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-google-community package and should be used instead. To use it run `pip install -U :class:`~langchain-google-community` and import as `from :class:`~langchain_google_community import GoogleDriveLoader``.\n",
      "  g_docs = GoogleDriveLoader(\n"
     ]
    }
   ],
   "source": [
    "docs_links = [\n",
    "    \"https://docs.google.com/document/d/1MvX9CTrVcoWg7WLAscq2MmnhTIrR0hZIGkpJMqhgflo/edit?tab=t.0\",\n",
    "    \"https://docs.google.com/document/d/1NcV9_JGjMfA4WlihW3vNTduy24NBWdy1RWXrA2W0BIk/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/193rx2Rh6u-Ud40k-rgnqSQs-94SvHdeXPrPxOWK59X0/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1vRDsn5o5mdymOEJ_O0tS4wcOjsAjt_2mLZqFfvgDUOs/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1JceLBII727AZzSrDFfdGthJ1G4PhCDsA8sEm_dQMVr0/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1yonU4qcysNkgd0BvbFmeIW9NF2ARErRJVW8QZynJyvM/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1bq2AE1Jy6cQFt1xgjqtkof12Lw6F6fujqTlN1nZnh0A/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1i-OcQeo7XOG83gS2ay2u0SLMWs4f8FG0JE_7l87qJkw/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1PyZE8v3S3aUY66lFn97q0vaXDHc60lyso2oUFP0htjY/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1Dudd7-6yl_UQrxfGa3MJZlKOfzHQdqWg0fb8Z9RzBec/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1cjhrhCccuwiIh0ujj8QeamJ2JHhI6CjPmO84t1DSRZ0/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1ESlfU6v8jseFlllZb3eaUeCJt69EIMsZiyMrDac-wX8/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1xQhAkC3oP2cb262EjaHCV6CxEgeEGUsKrC8pH2p6RiY/edit?usp=sharing\"\n",
    "    \n",
    "]\n",
    "\n",
    "g_docs = GoogleDriveLoader(\n",
    "    document_ids = [get_doc_id(i) for i in docs_links],\n",
    "    credentials_path = \"credentials_google.json\",\n",
    "    token_path = \"token.json\"\n",
    ").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f9dba0-a5b4-44db-8266-0f3e324d0674",
   "metadata": {},
   "source": [
    "Chroma seems to be a convenient alternative, as a chroma vectorstore can be converted directly into a retriever that returns k relevant documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8c95311-858e-4c5d-b856-b7b9ff4ba5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"wine_food_pairing_knowledge.pdf\"\n",
    "word = load_pdf(path)\n",
    "g_docs = g_docs + word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b795521-0dc5-49c4-bc4e-c527627787e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size = 300, \n",
    "    chunk_overlap = 50\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(g_docs)\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents = splits,\n",
    "    embedding = embd\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d77ae9-9457-4958-8bfd-25f627b52ac5",
   "metadata": {},
   "source": [
    "**Preparing Pydantic Schemas and LLM Modelfiles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2edbe6a2-6d35-4885-826f-7fe89de1adf1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class FoodPairing(BaseModel):\n",
    "    \"\"\"Information about a food item that pairs well with a wine.\"\"\"\n",
    "    \n",
    "    dish_name: Optional[str] = Field(\n",
    "        default=None, description=\"Name of the dish (e.g., 'roast duck', 'brie cheese').\"\n",
    "    )\n",
    "    pairing_type: Optional[str] = Field(\n",
    "        default=None, description=\"Type of pairing (e.g., 'complementary', 'contrast').\"\n",
    "    )\n",
    "    course: Optional[str] = Field(\n",
    "        default=None, description=\"Course type (e.g., 'starter', 'main', 'dessert').\"\n",
    "    )\n",
    "    description: Optional[str] = Field(\n",
    "        default=None, description=\"Description of the pairing experience or rationale.\"\n",
    "    )\n",
    "    suitability: Optional[int] = Field(\n",
    "        default=None, description=\"Suitability score or rating for the pairing (e.g., 1–10).\"\n",
    "    )\n",
    "    acidity: Optional[str] = Field(\n",
    "        default=None, description=\"Acidity match or contrast for the dish (e.g., 'low', 'crisp').\"\n",
    "    )\n",
    "    regional_pairing: Optional[str] = Field(\n",
    "        default=None, description=\"Regional or traditional pairing origin (e.g., 'Provence').\"\n",
    "    )\n",
    "    sweetness: Optional[str] = Field(\n",
    "        default=None, description=\"Sweetness level or match (e.g., 'dry', 'sweet').\"\n",
    "    )\n",
    "    \n",
    "\n",
    "class WineMetadata(BaseModel):\n",
    "    \"\"\"Structured metadata filters for querying a wine product database.\"\"\"\n",
    "\n",
    "    wine_name: Optional[str] = Field(\n",
    "        default=None, description=\"Specific wine name mentioned in the query.\"\n",
    "    )\n",
    "    variant_id: Optional[int] = Field(\n",
    "        default=None, description=\"Specific product variant ID.\"\n",
    "    )\n",
    "    size: Optional[str] = Field(\n",
    "        default=None, description=\"Bottle size (e.g., '750ml', '1.5L').\"\n",
    "    )\n",
    "    volume_unit: Optional[str] = Field(\n",
    "        default=None, description=\"Units for volume (e.g., 'ml', 'L').\"\n",
    "    )\n",
    "    rating: Optional[str] = Field(\n",
    "        default=None, description=\"Expert or user rating (e.g., '90+', '4.5 stars').\"\n",
    "    )\n",
    "    stock: Optional[int] = Field(\n",
    "        default=None, description=\"Stock availability if specified.\"\n",
    "    )\n",
    "\n",
    "    min_price: Optional[float] = Field(\n",
    "        default=None, description=\"Minimum price filter (inclusive).\"\n",
    "    )\n",
    "    max_price: Optional[float] = Field(\n",
    "        default=None, description=\"Maximum price filter (inclusive).\"\n",
    "    )\n",
    "\n",
    "    winemaker: Optional[str] = Field(\n",
    "        default=None, description=\"Name of the winemaker or producer.\"\n",
    "    )\n",
    "    vintage: Optional[int] = Field(\n",
    "        default=None, description=\"Vintage year of the wine (e.g., 2015).\"\n",
    "    )\n",
    "    country: Optional[str] = Field(\n",
    "        default=None, description=\"Country of origin.\"\n",
    "    )\n",
    "    region: Optional[str] = Field(\n",
    "        default=None, description=\"Region or appellation.\"\n",
    "    )\n",
    "    wine_type: Optional[str] = Field(\n",
    "        default=None, description=\"Type of wine (e.g., red, white, rosé, sparkling).\"\n",
    "    )\n",
    "    wine_grapes: Optional[str] = Field(\n",
    "        default=None, description=\"Grape variety or blend (e.g., Merlot, Syrah).\"\n",
    "    )\n",
    "\n",
    "    level_to_drink: Optional[str] = Field(\n",
    "        default=None, description=\"Drinkability status (e.g., 'drink now', 'ageing potential').\"\n",
    "    )\n",
    "    vinification: Optional[str] = Field(\n",
    "        default=None, description=\"Winemaking process (e.g., 'oak-aged', 'carbonic maceration').\"\n",
    "    )\n",
    "    season: Optional[str] = Field(\n",
    "        default=None, description=\"Season the wine is suited for (e.g., 'summer').\"\n",
    "    )\n",
    "    soil_type: Optional[str] = Field(\n",
    "        default=None, description=\"Soil characteristics (e.g., 'limestone', 'volcanic').\"\n",
    "    )\n",
    "\n",
    "    description: Optional[str] = Field(\n",
    "        default=None, description=\"Flavor notes or sensory descriptions.\"\n",
    "    )\n",
    "    occasion: Optional[str] = Field(\n",
    "        default=None, description=\"Occasion suitability (e.g., 'wedding', 'gift').\"\n",
    "    )\n",
    "\n",
    "    body: Optional[str] = Field(\n",
    "        default=None, description=\"Body type (e.g., 'light', 'full-bodied').\"\n",
    "    )\n",
    "    acidity: Optional[str] = Field(\n",
    "        default=None, description=\"Acidity level (e.g., 'crisp', 'low').\"\n",
    "    )\n",
    "    alcohol: Optional[float] = Field(\n",
    "        default=None, description=\"Alcohol content as a percentage (e.g., 13.5).\"\n",
    "    )\n",
    "    fruitiness: Optional[str] = Field(\n",
    "        default=None, description=\"Level of fruitiness (e.g., 'dry', 'juicy').\"\n",
    "    )\n",
    "    minerality: Optional[str] = Field(\n",
    "        default=None, description=\"Presence of mineral notes (e.g., 'chalky').\"\n",
    "    )\n",
    "    sweetness: Optional[str] = Field(\n",
    "        default=None, description=\"Sweetness level (e.g., 'dry', 'semi-sweet').\"\n",
    "    )\n",
    "    food_pairings: List[FoodPairing] = Field(\n",
    "        default=None,\n",
    "        description=\"List of recommended or matching food pairings.\"\n",
    "    )\n",
    "\n",
    "    def pretty_print(self) -> None:\n",
    "        for field_name, field in self.model_fields.items():\n",
    "            val = getattr(self, field_name)\n",
    "            if val is not None and val != field.default:\n",
    "                print(f\"{field_name}: {val}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b3951ec-46df-4018-8cc7-1be920c9ecec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for generating taste profiles\n",
    "\n",
    "system = \"\"\"You are an expert at converting user questions into wine taste profiles\n",
    "in the form of structured metadata\n",
    "\n",
    "Your job is to convert a user's question into a JSON object that matches the following schema:\n",
    "\n",
    "{\n",
    "  \"wine_name\": \"Optional[str]\",              // Specific wine name mentioned\n",
    "  \"winemaker\": \"Optional[str]\",              // Name of the winemaker or producer\n",
    "  \"vintage\": \"Optional[int]\",                // Vintage year (e.g. 2015)\n",
    "  \"country\": \"Optional[str]\",                // Country of origin\n",
    "  \"region\": \"Optional[str]\",                 // Region or appellation\n",
    "  \"wine_type\": \"Optional[str]\",              // Type of wine (e.g. red, white, rosé, sparkling)\n",
    "  \"wine_grapes\": \"Optional[str]\",            // Grape variety or blend (e.g. Merlot, Syrah)\n",
    "  \"level_to_drink\": \"Optional[str]\",         // Drinkability status (e.g. \"drink now\", \"ageing potential\")\n",
    "  \"vinification\": \"Optional[str]\",           // Wine-making process (e.g. \"oak-aged\", \"carbonic maceration\")\n",
    "  \"season\": \"Optional[str]\",                 // Season the wine is suited for (e.g. \"summer\", \"winter\")\n",
    "  \"soil_type\": \"Optional[str]\",              // Soil characteristics (e.g. \"limestone\", \"volcanic\")\n",
    "  \"description\": \"Optional[str]\",            // Flavor notes or sensory descriptions\n",
    "  \"occasion\": \"Optional[str]\",               // Occasion suitability (e.g. \"wedding\", \"gift\", \"everyday\")\n",
    "  \"body\": \"Optional[str]\",                   // Body type (e.g. \"light\", \"full-bodied\")\n",
    "  \"acidity\": \"Optional[str]\",                // Acidity level (e.g. \"crisp\", \"low\")\n",
    "  \"alcohol\": \"Optional[float]\",              // Alcohol content (as percentage, e.g. 13.5)\n",
    "  \"fruitiness\": \"Optional[str]\",             // Level of fruitiness (e.g. \"dry\", \"juicy\")\n",
    "  \"minerality\": \"Optional[str]\",             // Presence of mineral notes (e.g. \"chalky\", \"flinty\")\n",
    "  \"sweetness\": \"Optional[str]\",              // Sweetness level (e.g. \"dry\", \"semi-sweet\", \"sweet\")\n",
    "}\n",
    "\n",
    "Only include optional fields if they are explicitly mentioned in the user's query. \n",
    "Return the result as **pure JSON only**, with no code block, no Markdown, and no explanation.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50d4b3ff-daa1-44dd-b7d1-1f08f38275f1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "FIELD_MAP = {\n",
    "    \"wine_name\": \"Product Name\",\n",
    "    \"variant_id\": \"VariantID\",\n",
    "    \"size\": \"Size\",\n",
    "    \"volume_unit\": \"Volume Unit\",\n",
    "    \"rating\": \"Expert Ratings\",\n",
    "    \"stock\": \"Stock\",\n",
    "    \"min_price\": \"WS Retail Price\",\n",
    "    \"max_price\": \"WS Retail Price\",\n",
    "    \"winemaker\": \"Winemaker Name\",\n",
    "    \"vintage\": \"Vintage (Year)\",\n",
    "    \"country\": \"Country\",\n",
    "    \"region\": \"Region\",\n",
    "    \"wine_type\": \"Wine Type\",\n",
    "    \"wine_grapes\": \"Wine Grapes\",\n",
    "    \"season\": \"Season\",\n",
    "    \"soil_type\": \"Soil Type\",\n",
    "    \"occasion\": \"Occasion\",\n",
    "\n",
    "}\n",
    "    # \"level_to_drink\": \"Level to Drink\",\n",
    "    # \"description\": \"Description\",\n",
    "    # \"vinification\": \"Vinification Process\",\n",
    "    # \"body\": \"Body\",\n",
    "    # \"acidity\": \"Acidity\",\n",
    "    # \"alcohol\": \"Alcohol\",\n",
    "    # \"fruitiness\": \"Fruitiness\",\n",
    "    # \"minerality\": \"Minerality\",\n",
    "    # \"sweetness\": \"Sweetness / Dry\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb01f672-e880-49cd-986f-60930b18919d",
   "metadata": {},
   "source": [
    "**More helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "27dcfc86-f16d-4a6f-8a4a-ef84714bdc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwatch\n",
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "def timed(log_times):\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            start = time.time()\n",
    "            result = func(*args, **kwargs)\n",
    "            end = time.time()\n",
    "            log_times[func.__name__] = round(end - start, 4)\n",
    "            return result\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "log_times = {}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1ae98a79-0efc-47bd-a4fb-bf6d776dcfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timed(log_times)\n",
    "def query_analyzer(question: str) -> WineMetadata:\n",
    "    \"\"\"\n",
    "    Converts a natural language question into a structured query\n",
    "    using a spaCy custom NLP model.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=system),\n",
    "        HumanMessage(content=question)\n",
    "    ]\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    parsed_dict = extract_json_from_llm_output(response.content)\n",
    "    return WineMetadata(**parsed_dict)\n",
    "\n",
    "@timed(log_times)\n",
    "def filter_wines(data, model_instance, field_map, max_results=20):\n",
    "    \"\"\"\n",
    "    Given metadata filters constructed from user query using LLM,\n",
    "    returns first n wine profiles that match. \n",
    "    \"\"\"\n",
    "    filters = model_instance.model_dump(exclude_none=True)\n",
    "    results = []\n",
    "\n",
    "    for wine in data:\n",
    "        match = True\n",
    "        for key, value in filters.items():\n",
    "            if key in (\"food_pairings\"):\n",
    "                continue\n",
    "\n",
    "            if key not in field_map:\n",
    "                continue\n",
    "                \n",
    "            elif key in (\"min_price\", \"max_price\"):\n",
    "                price_field = field_map[key]\n",
    "                try:\n",
    "                    wine_price = float(wine.get(price_field,0))\n",
    "                except ValueError:\n",
    "                    match = False\n",
    "                    break\n",
    "                if key == \"min_price\" and wine_price < value:\n",
    "                    match = False\n",
    "                    break\n",
    "                if key == \"max_price\" and wine_price > value:\n",
    "                    match = False\n",
    "                    break\n",
    "\n",
    "            else:\n",
    "                field = field_map.get(key)\n",
    "                if field not in wine:\n",
    "                    match = False\n",
    "                    # print(f\"[MISSING] Field '{field}' missing in wine\")\n",
    "                    break\n",
    "                wine_val = normalize(wine[field])\n",
    "                query_val = normalize(value)\n",
    "                if query_val not in wine_val:\n",
    "                    # print(f\"[FAIL] {key}: '{query_val}' not in '{wine_val}' (wine: {wine.get('Product Name')})\")\n",
    "                    match = False\n",
    "                    break\n",
    "\n",
    "        if match:\n",
    "            results.append(wine)\n",
    "            if len(results)== max_results:\n",
    "                break\n",
    "\n",
    "    return results\n",
    "\n",
    "@timed(log_times)\n",
    "def create_taste_profile(parsed_query):\n",
    "    \"\"\"\n",
    "    Enriches food taste profile from user query using LLM.\n",
    "    \"\"\"\n",
    "    data = parsed_query.model_dump(exclude_none=True)\n",
    "\n",
    "    # Check if food_pairing exists and is not empty\n",
    "    food_pairings = data.get(\"food_pairings\")\n",
    "    pairing_descriptions = []\n",
    "    if food_pairings:\n",
    "        # Extract raw attributes\n",
    "        for pairing in food_pairings:\n",
    "            if isinstance(pairing, dict):\n",
    "                entries = [f\"{key}: {value}\" for key, value in pairing.items() if value]\n",
    "                block = \"\\n\".join(entries)\n",
    "                pairing_descriptions.append(block)\n",
    "            else:\n",
    "                try:\n",
    "                    entries = [f\"{key}: {getattr(pairing, key)}\" for key in pairing.__fields__ if getattr(pairing, key)]\n",
    "                    block = \"\\n\".join(entries)\n",
    "                    pairing_descriptions.append(block)\n",
    "                except:\n",
    "                    continue\n",
    "        raw_input = \"\\n\\n---\\n\\n\".join(pairing_descriptions)\n",
    "\n",
    "        # RAG\n",
    "        response = qa_chain.invoke(f\"Create a taste profile based on the following context: {raw_input}\")\n",
    "        return response[\"result\"]\n",
    "    return None               \n",
    "\n",
    "@timed(log_times)\n",
    "def generate_recommendations(filtered, profile, top_k=5):\n",
    "    \"\"\"\n",
    "    Performs similarity search between embeddings of (a) each of the filtered wines\n",
    "    and (b) enriched taste profile from query, if present otherwise randomly \n",
    "    sample 3 wines (cheapest -> middle -> most expensive)\n",
    "    \"\"\"\n",
    "    if len(filtered) == 0:\n",
    "        return None\n",
    "        \n",
    "    if len(filtered) < top_k:\n",
    "        return filtered\n",
    "        \n",
    "    if profile:\n",
    "        # print(\"yay\")\n",
    "        embedded_wines = []\n",
    "        for wine in filtered:\n",
    "            # print(wine)\n",
    "            content = \"\\n\".join(f\"{key}: {value}\" for key, value in wine.items() if value)\n",
    "            wine_embed = embd.embed_query(content)\n",
    "            embedded_wines.append((wine, wine_embed))\n",
    "\n",
    "        profile_embed = embd.embed_query(profile)\n",
    "        scored_embed = [(wine, cosine_similarity(profile_embed, wine_embed)) for wine, wine_embed in embedded_wines]\n",
    "        top_wines = sorted(scored_embed, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "        return [wine for wine, _ in top_wines]\n",
    "\n",
    "    else:\n",
    "        # print(\"nooo\")\n",
    "        sorted_wines = sorted(filtered, key=lambda x: float(x.WS_Retail_Price))\n",
    "        n = len(sorted_wines)\n",
    "        if n == 0:\n",
    "            return []\n",
    "        step = max(1, n // top_k)\n",
    "        sampled = [random.choice(sorted_wines[i:i+step]) for i in range(0, n, step)][:top_k]\n",
    "\n",
    "        return sampled \n",
    "\n",
    "def ask_ai(question, data, field_map):\n",
    "    start_main = time.time()\n",
    "    parsed_query = query_analyzer(question)\n",
    "    filtered = filter_wines(data=data, model_instance=parsed_query, field_map=field_map)\n",
    "    profile = create_taste_profile(parsed_query)\n",
    "    recommendations = generate_recommendations(filtered, profile)\n",
    "\n",
    "    \n",
    "    total_time = round(time.time() - start_main, 4)\n",
    "    # Print timing summary\n",
    "    print(\"Timing summary:\")\n",
    "    for name, duration in log_times.items():\n",
    "        print(f\"  {name}: {duration} seconds\")\n",
    "    print(f\"  Total time: {total_time} seconds\")\n",
    "\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf8b1294-abe1-41b0-be5a-34fd8cd70ddf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "wine_data = \"wine_data.csv\"\n",
    "food_data = \"food_data.csv\"\n",
    "\n",
    "wine_df = pd.read_csv(wine_data)\n",
    "food_df = pd.read_csv(food_data)\n",
    "\n",
    "wine_json = wine_df.to_dict(orient=\"records\")\n",
    "food_json = food_df.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2400d945-5488-49db-b195-b514f979d3ec",
   "metadata": {},
   "source": [
    "### Wine-Food Pairing Tests\n",
    "\n",
    "Questions:\n",
    "1. What wine goes well with spicy Thai green curry with coconut milk?\n",
    "2. Recommend a red wine under 300 HKD that pairs well with grilled lamb and comes from Spain\n",
    "3. Suggest a celebratory wine that works with oysters and has high acidity.\n",
    "4. I'm cooking mushroom risotto and want something medium-bodied and earthy to go with it.\n",
    "5. Pair a bold Napa Cabernet Sauvignon with sushi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3d63cae9-03bf-4836-a7d3-b1e0badf7a1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What wine goes well with spicy Thai green curry with coconut milk?\n",
      "Timing summary:\n",
      "  query_analyzer: 11.4839 seconds\n",
      "  filter_wines: 0.0 seconds\n",
      "  create_taste_profile: 39.4799 seconds\n",
      "  generate_recommendations: 2.3598 seconds\n",
      "  Total time: 53.3235 seconds\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'recommendations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[93]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(questions[i])  \u001b[38;5;66;03m# Correct variable name\u001b[39;00m\n\u001b[32m     12\u001b[39m recommendation = ask_ai(question=questions[i], data=wine_json, field_map=FIELD_MAP)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrecommendations\u001b[49m == \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNo recommendations found\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'recommendations' is not defined"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "\"What wine goes well with spicy Thai green curry with coconut milk?\",\n",
    "\"Recommend a red wine under 300 HKD that pairs well with grilled lamb and comes from Spain\",\n",
    "\"Suggest a celebratory wine that works with oysters and has high acidity.\",\n",
    "\"I'm cooking mushroom risotto and want something medium-bodied and earthy to go with it.\",\n",
    "\"Pair a bold Napa Cabernet Sauvignon with sushi.\",\n",
    "]\n",
    "\n",
    "for i in range(1):\n",
    "# for i in range(2, 5, 2):\n",
    "    print(questions[i])  # Correct variable name\n",
    "    recommendation = ask_ai(question=questions[i], data=wine_json, field_map=FIELD_MAP)\n",
    "    if recommendation == None:\n",
    "        print(\"No recommendations found\")\n",
    "        continue\n",
    "\n",
    "    for j in range(5):\n",
    "        try:\n",
    "            print(f\"Wine {j+1}:\", recommendation[j]['Product Name'])\n",
    "        except:\n",
    "            print(\"No more suggested wines\")\n",
    "            continue\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6960a0b-ec16-46aa-a038-1bea79a87a75",
   "metadata": {},
   "source": [
    "### Food-Wine Pairing Tests\n",
    "\n",
    "Questions\n",
    "1. What are the best dishes to serve with a 2020 Puligny-Montrachet Chardonnay?\n",
    "2. I have a bottle of Amarone della Valpolicella — what foods would pair well with it?\n",
    "3. What should I cook for dinner to go with a chilled bottle of Sancerre?\n",
    "4. Can you suggest a full-course meal to go with a vintage Champagne?\n",
    "5. What kind of food works well with a sweet Riesling from Mosel?\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "870ad854-df33-4428-b197-e83425e54850",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Base Models for Reverse Pairings\n",
    "class WinePairing(BaseModel):\n",
    "    \"\"\"Structured metadata filters for querying a wine product database.\"\"\"\n",
    "\n",
    "    wine_name: Optional[str] = Field(\n",
    "        default=None, description=\"Specific wine name mentioned in the query.\"\n",
    "    )\n",
    "    wine_type: Optional[str] = Field(\n",
    "        default=None, description=\"Type of wine (e.g., red, white, rosé, sparkling).\"\n",
    "    )\n",
    "    wine_grapes: Optional[str] = Field(\n",
    "        default=None, description=\"Grape variety or blend (e.g., Merlot, Syrah).\"\n",
    "    )\n",
    "    level_to_drink: Optional[str] = Field(\n",
    "        default=None, description=\"Drinkability status (e.g., 'drink now', 'ageing potential').\"\n",
    "    )\n",
    "    season: Optional[str] = Field(\n",
    "        default=None, description=\"Season the wine is suited for (e.g., 'summer').\"\n",
    "    )\n",
    "    description: Optional[str] = Field(\n",
    "        default=None, description=\"Flavor notes or sensory descriptions.\"\n",
    "    )\n",
    "    occasion: Optional[str] = Field(\n",
    "        default=None, description=\"Occasion suitability (e.g., 'wedding', 'gift').\"\n",
    "    )\n",
    "    body: Optional[str] = Field(\n",
    "        default=None, description=\"Body type (e.g., 'light', 'full-bodied').\"\n",
    "    )\n",
    "    acidity: Optional[str] = Field(\n",
    "        default=None, description=\"Acidity level (e.g., 'crisp', 'low').\"\n",
    "    )\n",
    "    alcohol: Optional[float] = Field(\n",
    "        default=None, description=\"Alcohol content as a percentage (e.g., 13.5).\"\n",
    "    )\n",
    "    fruitiness: Optional[str] = Field(\n",
    "        default=None, description=\"Level of fruitiness (e.g., 'dry', 'juicy').\"\n",
    "    )\n",
    "    minerality: Optional[str] = Field(\n",
    "        default=None, description=\"Presence of mineral notes (e.g., 'chalky').\"\n",
    "    )\n",
    "    sweetness: Optional[str] = Field(\n",
    "        default=None, description=\"Sweetness level (e.g., 'dry', 'semi-sweet').\"\n",
    "    )\n",
    "\n",
    "\n",
    "class FoodMetadata(BaseModel):\n",
    "    \"\"\"Structured metadata filters for querying a food product database.\"\"\"\n",
    "    \n",
    "    dish_name: Optional[str] = Field(\n",
    "        default=None, description=\"Name of the dish (e.g., 'roast duck', 'brie cheese').\"\n",
    "    )\n",
    "    min_price: Optional[float] = Field(\n",
    "        default=None, description=\"Minimum price filter (inclusive).\"\n",
    "    )\n",
    "    max_price: Optional[float] = Field(\n",
    "        default=None, description=\"Maximum price filter (inclusive).\"\n",
    "    )\n",
    "    type: Optional[str] = Field(\n",
    "        default=None, description=\"Food type (e.g., 'fruit', 'pastry', 'vegetarian').\"\n",
    "    )\n",
    "    course: Optional[str] = Field(\n",
    "        default=None, description=\"Course (e.g., 'starter', 'main', 'dessert').\"\n",
    "    )\n",
    "    description: Optional[str] = Field(\n",
    "        default=None, description=\"Description of the dish.\"\n",
    "    )\n",
    "    acidity: Optional[str] = Field(\n",
    "        default=None, description=\"Acidity match or contrast for the dish (e.g., 'low', 'crisp').\"\n",
    "    )\n",
    "    regional_pairing: Optional[str] = Field(\n",
    "        default=None, description=\"Regional or traditional pairing origin (e.g., 'Provence').\"\n",
    "    )\n",
    "    sweetness: Optional[str] = Field(\n",
    "        default=None, description=\"Sweetness level or match (e.g., 'dry', 'sweet').\"\n",
    "    )\n",
    "    wine_pairings: List[WinePairing] = Field(\n",
    "        default=None,\n",
    "        description=\"List of recommended or matching wine pairings.\"\n",
    "    )\n",
    "\n",
    "    def pretty_print(self) -> None:\n",
    "        for field_name, field in self.model_fields.items():\n",
    "            val = getattr(self, field_name)\n",
    "            if val is not None and val != field.default:\n",
    "                print(f\"{field_name}: {val}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "22e2e5e6-6731-4ba1-b26a-47cfcdd70f07",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "food_system = \"\"\"You are an expert at converting user questions into structured metadata filters \n",
    "to query a database of food products\n",
    "\n",
    "Your job is to convert a user's question into a JSON object that matches the following schema:\n",
    "            \n",
    "{\n",
    "    \"dish_name\": \"Optional[str]\",                 // Name of the dish (e.g., 'roast duck', 'brie cheese').\n",
    "    \"min_price\": \"Optional[float]\" ,              // Minimum price filter (inclusive).\n",
    "    \"max_price\": \"Optional[float]\" ,              // Maximum price filter (inclusive).\n",
    "    \"type\": \"Optional[str]\" ,                     // Food type (e.g., 'fruit', 'pastry', 'vegetarian').\n",
    "    \"course\": \"Optional[str]\" ,                   // Course (e.g., 'starter', 'main', 'dessert').\n",
    "    \"description\": \"Optional[str]\" ,              // Description of the dish.\n",
    "    \"acidity\": \"Optional[str]\" ,                  // Acidity match or contrast for the dish (e.g., 'low', 'crisp').\n",
    "    \"regional_pairing\": \"Optional[str]\" ,         // Regional or traditional pairing origin (e.g., 'Provence').\n",
    "    \"sweetness\": \"Optional[str]\" ,                // Sweetness level or match (e.g., 'dry', 'sweet').\n",
    "\n",
    "    \"wine_pairings\": [                            // Optional: List of recommended food matches\n",
    "    {\n",
    "          \"wine_name\": \"Optional[str]\",              // Specific wine name mentioned\n",
    "          \"wine_type\": \"Optional[str]\",              // Type of wine (e.g. red, white, rosé, sparkling)\n",
    "          \"wine_grapes\": \"Optional[str]\",            // Grape variety or blend (e.g. Merlot, Syrah)\n",
    "          \"level_to_drink\": \"Optional[str]\",         // Drinkability status (e.g. \"drink now\", \"ageing potential\")\n",
    "          \"season\": \"Optional[str]\",                 // Season the wine is suited for (e.g. \"summer\", \"winter\")        \n",
    "          \"description\": \"Optional[str]\",            // Flavor notes or sensory descriptions\n",
    "          \"occasion\": \"Optional[str]\",               // Occasion suitability (e.g. \"wedding\", \"gift\", \"everyday\")\n",
    "          \"body\": \"Optional[str]\",                   // Body type (e.g. \"light\", \"full-bodied\")\n",
    "          \"acidity\": \"Optional[str]\",                // Acidity level (e.g. \"crisp\", \"low\")\n",
    "          \"alcohol\": \"Optional[float]\",              // Alcohol content (as percentage, e.g. 13.5)\n",
    "          \"fruitiness\": \"Optional[str]\",             // Level of fruitiness (e.g. \"dry\", \"juicy\")\n",
    "          \"minerality\": \"Optional[str]\",             // Presence of mineral notes (e.g. \"chalky\", \"flinty\")\n",
    "          \"sweetness\": \"Optional[str]\",              // Sweetness level (e.g. \"dry\", \"semi-sweet\", \"sweet\")\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "Only include optional fields if they are explicitly mentioned in the user's query. \n",
    "Return the result as **pure JSON only**, with no code block, no Markdown, and no explanation.\n",
    "\"\"\"\n",
    "\n",
    "food_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", food_system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9d0884cc-3bf6-4d20-bea7-4c5d35ac222f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "FOOD_FIELD_MAP = {\n",
    "    \"dish_name\": \"Product Name\",\n",
    "    \"price\": \"Price\",\n",
    "    \"type\": \"Food Type\",\n",
    "    \"course\": \"Course\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f56fefc-8bfd-4a7c-b9a6-b951adc0b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "def timed(log_times):\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            start = time.time()\n",
    "            result = func(*args, **kwargs)\n",
    "            end = time.time()\n",
    "            log_times[func.__name__] = round(end - start, 4)\n",
    "            return result\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "log_times = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "feb3f583-ede1-40dc-b2ec-0a22b33fed9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timed(log_times)\n",
    "def food_query_analyzer(question: str) -> FoodMetadata:\n",
    "    \"\"\"\n",
    "    Converts a natural language question into a structured query\n",
    "    using a DeepSeek LLM backend.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=food_system),\n",
    "        HumanMessage(content=question)\n",
    "    ]\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    print(response.content)\n",
    "    parsed_dict = extract_json_from_llm_output(response.content)\n",
    "    return FoodMetadata(**parsed_dict)\n",
    "\n",
    "@timed(log_times)\n",
    "def filter_food(data, model_instance, field_map, max_results=20):\n",
    "    \"\"\"\n",
    "    Given metadata filters constructed from user query using LLM,\n",
    "    returns first n wine profiles that match. \n",
    "    \"\"\"\n",
    "    filters = model_instance.model_dump(exclude_none=True)\n",
    "    results = []\n",
    "\n",
    "    for food in data:\n",
    "        match = True\n",
    "        for key, value in filters.items():\n",
    "            if key not in field_map:\n",
    "                continue\n",
    "                \n",
    "            elif key in (\"min_price\", \"max_price\"):\n",
    "                price_field = field_map[key]\n",
    "                try:\n",
    "                    food_price = float(food.get(price_field,0))\n",
    "                except ValueError:\n",
    "                    match = False\n",
    "                    break\n",
    "                if key == \"min_price\" and food_price < value:\n",
    "                    match = False\n",
    "                    break\n",
    "                if key == \"max_price\" and food_price > value:\n",
    "                    match = False\n",
    "                    break\n",
    "\n",
    "            else:\n",
    "                field = field_map.get(key)\n",
    "                if field not in food:\n",
    "                    match = False\n",
    "                    # print(f\"[MISSING] Field '{field}' missing in wine\")\n",
    "                    break\n",
    "                food_val = normalize(food[field])\n",
    "                query_val = normalize(value)\n",
    "                if query_val not in food_val:\n",
    "                    # print(f\"[FAIL] {key}: '{query_val}' not in '{wine_val}' (wine: {wine.get('Product Name')})\")\n",
    "                    match = False\n",
    "                    break\n",
    "\n",
    "        if match:\n",
    "            results.append(food)\n",
    "            if len(results)== max_results:\n",
    "                break\n",
    "\n",
    "    return results\n",
    "\n",
    "@timed(log_times)\n",
    "def create_taste_profile(parsed_query):\n",
    "    \"\"\"\n",
    "    Enriches wine taste profile from user query using LLM.\n",
    "    \"\"\"\n",
    "    data = parsed_query.model_dump(exclude_none=True)\n",
    "\n",
    "    # Check if food_pairing exists and is not empty\n",
    "    wine_pairings = data.get(\"wine_pairings\")\n",
    "    pairing_descriptions = []\n",
    "    if wine_pairings:\n",
    "        # Extract raw attributes\n",
    "        for pairing in wine_pairings:\n",
    "            if isinstance(pairing, dict):\n",
    "                entries = [f\"{key}: {value}\" for key, value in pairing.items() if value]\n",
    "                block = \"\\n\".join(entries)\n",
    "                pairing_descriptions.append(block)\n",
    "            else:\n",
    "                try:\n",
    "                    entries = [f\"{key}: {getattr(pairing, key)}\" for key in pairing.__fields__ if getattr(pairing, key)]\n",
    "                    block = \"\\n\".join(entries)\n",
    "                    pairing_descriptions.append(block)\n",
    "                except:\n",
    "                    continue\n",
    "        raw_input = \"\\n\\n---\\n\\n\".join(pairing_descriptions)\n",
    "\n",
    "        # RAG\n",
    "        response = qa_chain.invoke(f\"Create a taste profile based on the following context: {raw_input}\")\n",
    "        return response[\"result\"]\n",
    "    return None                       \n",
    "\n",
    "@timed(log_times)\n",
    "def generate_recommendations(filtered, profile, top_k=5):\n",
    "    \"\"\"\n",
    "    Performs similarity search between embeddings of (a) each of the filtered wines\n",
    "    and (b) enriched taste profile from query, if present otherwise randomly \n",
    "    sample 3 wines (cheapest -> middle -> most expensive)\n",
    "    \"\"\"\n",
    "    if len(filtered) == 0:\n",
    "        return None\n",
    "        \n",
    "    if len(filtered) < top_k:\n",
    "        return filtered\n",
    "        \n",
    "    if profile:\n",
    "        # print(\"yay\")\n",
    "        embedded_food = []\n",
    "        for food in filtered:\n",
    "            # print(wine)\n",
    "            content = \"\\n\".join(f\"{key}: {value}\" for key, value in food.items() if value)\n",
    "            food_embed = embd.embed_query(content)\n",
    "            embedded_food.append((food, food_embed))\n",
    "\n",
    "        profile_embed = embd.embed_query(profile)\n",
    "        scored_embed = [(food, cosine_similarity(profile_embed, food_embed)) for food, food_embed in embedded_food]\n",
    "        top_food = sorted(scored_embed, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "        return [food for food, _ in top_food]\n",
    "\n",
    "    else:\n",
    "        # print(\"nooo\")\n",
    "        sorted_wines = sorted(filtered, key=lambda x: float(x.WS_Retail_Price))\n",
    "        n = len(sorted_wines)\n",
    "        if n == 0:\n",
    "            return []\n",
    "        step = max(1, n // top_k)\n",
    "        sampled = [random.choice(sorted_wines[i:i+step]) for i in range(0, n, step)][:top_k]\n",
    "\n",
    "        return sampled \n",
    "\n",
    "@timed(log_times)\n",
    "def ask_food_ai(question, data, field_map):\n",
    "    start_main = time.time()\n",
    "    parsed_query = food_query_analyzer(question)\n",
    "    # parsed_query.pretty_print()\n",
    "    filtered = filter_wines(data=data, model_instance=parsed_query, field_map=field_map)\n",
    "    # print(\"\\n\\nFiltered:\", filtered)\n",
    "    profile = create_taste_profile(parsed_query)\n",
    "    # print(\"\\n\\nProfile:\", profile)\n",
    "    recommendations = generate_recommendations(filtered, profile)\n",
    "    # print(recommendations)\n",
    "    \n",
    "    total_time = round(time.time() - start_main, 4)\n",
    "    # Print timing summary\n",
    "    print(\"Timing summary:\")\n",
    "    for name, duration in log_times.items():\n",
    "        print(f\"  {name}: {duration} seconds\")\n",
    "    print(f\"  Total time: {total_time} seconds\")\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "da58e8eb-2e3d-49d1-b990-bf644be4db1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the best dishes to serve with a 2020 Puligny-Montrachet Chardonnay?\n",
      "Timing summary:\n",
      "  query_analyzer: 11.4839 seconds\n",
      "  filter_wines: 0.0 seconds\n",
      "  create_taste_profile: 46.7189 seconds\n",
      "  generate_recommendations: 1.7185 seconds\n",
      "  food_query_analyzer: 7.6931 seconds\n",
      "  Total time: 56.1305 seconds\n",
      "Food 1: Alsatian Apple Tart with Caramelized Pecans\n",
      "Food 2: Bacalhau à Brás\n",
      "Food 3: Apple and Brie Tartlets with Caramelized Onions\n",
      "Food 4: Alsatian Bacon and Onion Tart\n",
      "Food 5: Baked Camembert with Fig Jam\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "\"What are the best dishes to serve with a 2020 Puligny-Montrachet Chardonnay?\"\n",
    "]\n",
    "\n",
    "for i in range(len(questions)):\n",
    "# for i in range(2, 5, 2):\n",
    "    print(questions[i])  # Correct variable name\n",
    "    recommendation = ask_food_ai(question=questions[i], data = food_json, field_map = FOOD_FIELD_MAP)\n",
    "    if recommendation == None:\n",
    "        print(\"No recommendation found\")\n",
    "        continue\n",
    "\n",
    "    for j in range(5):\n",
    "        try:\n",
    "            print(f\"Food {j+1}:\", recommendation[j]['Product Name'])\n",
    "        except:\n",
    "            print(\"No more suggested food\")\n",
    "            continue\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "17f1eb70-3ef6-4828-b4d2-11713037e441",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'Model Not Exist', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[101]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m question = \u001b[33m\"\u001b[39m\u001b[33mWhat are the best dishes to serve with a 2020 Puligny-Montrachet Chardonnay?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m start_main = time.time()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m parsed_query = \u001b[43mfood_query_analyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m end_time = time.time()\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtime:\u001b[39m\u001b[33m\"\u001b[39m, {\u001b[38;5;28mround\u001b[39m(end_time - start_main, \u001b[32m4\u001b[39m)})\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[89]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mtimed.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m      9\u001b[39m     start = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     end = time.time()\n\u001b[32m     12\u001b[39m     log_times[func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28mround\u001b[39m(end - start, \u001b[32m4\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[96]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mfood_query_analyzer\u001b[39m\u001b[34m(question)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03mConverts a natural language question into a structured query\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03musing a DeepSeek LLM backend.\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      7\u001b[39m messages = [\n\u001b[32m      8\u001b[39m     SystemMessage(content=food_system),\n\u001b[32m      9\u001b[39m     HumanMessage(content=question)\n\u001b[32m     10\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m response = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.content)\n\u001b[32m     14\u001b[39m parsed_dict = extract_json_from_llm_output(response.content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\rag-env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:372\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    362\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    367\u001b[39m     **kwargs: Any,\n\u001b[32m    368\u001b[39m ) -> BaseMessage:\n\u001b[32m    369\u001b[39m     config = ensure_config(config)\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    371\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    382\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\rag-env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:957\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    948\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    950\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    954\u001b[39m     **kwargs: Any,\n\u001b[32m    955\u001b[39m ) -> LLMResult:\n\u001b[32m    956\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\rag-env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:776\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    775\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    782\u001b[39m         )\n\u001b[32m    783\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    784\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\rag-env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1022\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1020\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1026\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\rag-env\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1071\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1069\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n\u001b[32m   1070\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1071\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, generation_info)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\rag-env\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\rag-env\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:925\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    922\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    923\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    924\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\rag-env\\Lib\\site-packages\\openai\\_base_client.py:1249\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1235\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1236\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1237\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1244\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1245\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1246\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1247\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1248\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\rag-env\\Lib\\site-packages\\openai\\_base_client.py:1037\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1034\u001b[39m             err.response.read()\n\u001b[32m   1036\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': 'Model Not Exist', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}"
     ]
    }
   ],
   "source": [
    "question = \"What are the best dishes to serve with a 2020 Puligny-Montrachet Chardonnay?\"\n",
    "start_main = time.time()\n",
    "parsed_query = food_query_analyzer(question)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"time:\", {round(end_time - start_main, 4)})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-env",
   "language": "python",
   "name": "rag-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
