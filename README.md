### Still in development...

This connects my 2 repositories (rag-wine-recommendation and custom-nlp-parser) to create a unified pipeline for deployment. 
Intent recognition and Named Entity Recognition (NER) spaCy models are trained to generate metadata filters from user query with low latency.
I will be using HyDE (Hypothetical Document Embeddings, after filtering the metadata. 
- First, a short, JSON hypothetical answer to query is generated by an LLM corresopnding to the schema of wine csv database.
- Next, this is embedded and a similarity search is performed between the HyDE and top k filtered wines.
- Finally, RAG model using Bedrock LLMs will be used to generate reasoning for the suggested top 5 wines.

## Current problems (optimization):
### 1. Initial Filter
- implement re-ranking, make more inclusive (rn only first 20 valid entries) -> train custom re-ranker model
- fix some issues with filtering wine types

### 2. Nlp model. 
- train intent recognition and NER model on more data.
- add labels

### 3. LLM models
- explore other LLM models for generating taste profiles and reasoning
- DeepSeek outperforms Llama in quality of generated taste profiles, despite higher latency

## Cloud Deployment
- refactored code wrapped with endpoints using FastAPI, to be stored inside a Docker image
- use Mangum as API handler adapter to ensure compatibility with AWS Lambda
- setup CDK and AWS Lambda
